# 计算机网络

## IO多路复用

### 阻塞IO是什么？如何优化？



## 什么是以太网

​	什么是以太⽹呢？电脑上的以太⽹接⼝， Wi-Fi接⼝，以太⽹交换机、路由器上的千兆，万兆以太⽹⼝，还有⽹线，它们都是以太⽹的组成部分。**以太⽹就是⼀种在「局域⽹」内，把附近的设备连接起来，使它们之间可以进⾏通讯的技术**。

以太⽹在判断⽹络包⽬的地时和 IP 的⽅式不同，因此必须采⽤相匹配的⽅式才能在以太⽹中将包发往⽬的地，⽽ MAC 头部就是⼲这个⽤的，所以，**在以太⽹进⾏通讯要⽤到 MAC** 地址。

MAC 头部是以太网使用的头部，它包含了接收⽅和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。



## 每一层数据包的叫法

⽹络接⼝层的传输单位是帧（frame）， IP 层的传输单位是包（packet）， TCP 层的传输单位是段（segment）， HTTP 的传输单位则是消息或报⽂（message）  



## 域名解析的流程

<img src="img/domain-name-solve.JPG" style="zoom:67%;" />

**域名解析的缓存**：

1. 浏览器缓存
2. hosts文件
3. 操作系统DNS缓存



## 协议栈

主要协议包含：

- TCP：传输层协议，提供可靠传输，流量控制，拥塞控制，按序交付
- UDP：传输层协议，不可靠传输，无流量控制，无拥塞控制，不保证顺序
- ICMP：网络层协议，⽤于告知⽹络包传送过程中产⽣的错误以及各种控制信息  
  - **错误报告**：当IP数据包在传输过程中出现错误时，如目标主机不可达、网络不可达、协议不可达、端口不可达、数据包生存时间（TTL）过期等，接收主机或路由器会生成一个ICMP错误报文，发送给原始数据包的发送者。
  - **网络诊断**：ICMP提供了一些用于网络诊断的工具，如ping和traceroute。Ping使用ICMP回显请求和回显应答报文来测试网络连接。Traceroute则通过发送一系列TTL值逐渐增大的IP数据包，并依据返回的ICMP超时报文，来追踪数据包从源主机到目标主机的路径
- ARP：⽤于根据 IP 地址查询相应的以太⽹ MAC 地址  

1. **ARP请求**：
   - 当一台主机（如A）需要与另一台主机（如B）通信时，A需要知道B的MAC地址。
   - A会先检查自己的ARP缓存（一个存储IP地址到MAC地址映射的表）中是否有B的MAC地址。
   - 如果没有，**A会广播一个ARP请求包到局域网，ARP请求包中包含B的IP地址**。
2. **ARP响应**：
   - 局域网中的所有主机都会接收到这个ARP请求包，**但只有拥有该IP地址的主机（即B）会响应**。
   - B会发送一个ARP响应包，包含自己的MAC地址，直接发送给A。
3. **更新ARP缓存**：
   - A收到ARP响应包后，会将B的IP地址和MAC地址映射存储在自己的ARP缓存中，以便下次通信时直接使用，不再需要发送ARP请求。





### TCP

#### 长连接与短链接

##### http长连接

http采用的是“应答-请求”模式，在http没有设置长连接选项的时候，当浏览器和服务器通过TCP完成三次连接，然后发送http报文、得到响应后，就会发送四次挥手断开连接。 

这样的方式实在麻烦，于是http提供了长连接选项。也就是同一个TCP连接来接受和发送多个HTTP请求/应答，避免了连接简历和释放的开销。

Http的长连接还是http流水线实现的基础——所谓的流水线就是客户端可以一次性发送多个请求，而在发送的过程中不需要等待服务器的回应。在http1.1中虽然有流水线，但是服务端还是顺序响应，也就是第一个请求到来后，必须第一个请求处理了才能处理后续的请求。也就是发生 **队头阻塞**。

为了避免资源浪费,web服务软件一般会有一个keep alive计时器。

> HTTP1.1规定了默认保持长连接（HTTP persistent connection ，也有翻译为持久连接），数据传输完成了保持TCP连接不断开（不发RST包、不四次握手）

##### tcp长连接

tcp的keep alive是一个TCP保活机制，它的原理就是如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。

+ 这样的话，只要对端程序是正常的，那么TCP保活探测报文发过去后，对端就会正常响应，这样TCP保活时间就会被重置。
+ 如果宕机，TCP保活探测报文发给对端后，没有响应，再重发几次后，就会断开。



#### TCP与UDP的区别

1. TCP是面向连接的协议，传输数据前要建立连接，UPD不需要建立连接，可以即刻传递
2. TCP是点对点的服务，UDP支持一对一，一对多的交互通信。
3. TCP是可靠交付数据的；UDP是尽最大努力交付，不保证可靠交付。可以通过QUIC协议实现一个基于UDP的可靠传输协议
4. TCP的首部比较长，在没有使用选项都是20字节，使用了更长；UDP首部只有8字节，且是固定的--> 源端口+目标端口+包长度+校验和
5. TCP是面向字节流；UDP是面向数据包的。
6. 分片不同。TCP的数据如果超过了MSS它在传输层就会分片，所以目标主机收到后也会在传输层进行拼接。如果中途分片丢失了只会重传这一个分片；而UDP是数据大小如果超过MTU，在IP层分片，目标主机收到后，会在IP层进行拼接然后传给传输层。



#### QUIC实现UDP可靠传输

#### 应用层怎么解决UDP的错包问题

1. #### 添加序列号，保证数据顺序到达：

+ 发送方：在每个 UDP 数据包的开头附加一个递增的 **序列号**。
+ 接收方：接收数据时检查序列号，根据序列号对数据进行排序。如果数据包乱序，需要重新排序，或丢弃过时的数据。

2. 在应用层实现类似TCP重传的机制：

+ 发送方：发送数据包后，等待接收方的确认（ACK）消息。如果超过一定时间未收到 ACK，重新发送该数据包。
+ 接收方：接收到数据包后，向发送方回送一个包含序列号的 ACK。检测是否有丢失的情况，并请求重传。

3. 数据校验：

+ 发送方：在发送前对数据计算校验值，并将其附加到数据包中。
+ 接收方：对收到的数据计算校验值，并与发送方的校验值进行比较。如果校验失败则丢弃数据，并请求重传。

4. 应用层分片

+ 应用层检查数据大小是否需要分片。

#### 键入网址到网页显示，期间发生了什么

1. 浏览器解析URL，确定web服务器和资源
2. 生成HTTP请求
3. 通过DNS找到服务器域名对应的IP地址

> DNS查找流程：
>
> 1. 先看浏览器缓存
> 2. 再看操作系统缓存
> 3. hosts文件查看
> 4. 本地DNS服务器
> 5. 根域名服务器，它会转发一个顶级域名服务器地址
> 6. 访问顶级域名服务器，转发权威DNS服务器地址
> 7. 访问权威DNS域名，转发域名对应的IP地址

4. 浏览器和服务器建立TCP连接（如果是HTTPS的话还有TLS四次握手
5. 将2中生成的请求交给内核网络协议栈

> 应用执行系统调用，把要发送的数据写到socket的缓存区，然后加入TCP头、IP头、MAC头

6. 网卡驱动将数据写入网卡DMA区域
7. 网卡从DMA区域读取数据发送出去
8. 然后经过交换机原样转发出去，由路由器继续转发

> 路由器接收到数据包后，去掉MAC头，根据IP头继续包的转发。通过路由器表判断转发目标，获取网关列从而获取转发的目标IP地址
>
> 根据IP地址通过ARP查询MAC地址；转发

9. 当数据包到达服务器网卡的时候，网卡写入DMA区域（ring buffer)
10. 内核网络栈开始处理数据包--> 取出MAC头，验证MAC地址；取出IP头，检查IP是否符合，是否是TCP；取出TCP头，查看序列号等；把数据放入接受缓存区
11. 服务器接收到数据包后，将请求的网页内存装到HTTP响应报文中，发送出去
12. 浏览器收到HTTP报文后，就可以解析找个HTML文件成DOM树结构了，然后执行渲染。

#### 三次握手的建立

<img src="img/tcp-3-hand.JPG" style="zoom:50%;" />

可以通过`netstat -napt`来查询TCP的连接状态。

三次握手中**第三次握手是可以携带数据的。**

#### 为什么TCP是三次握手，不是两次或者四次

首先，TCP连接是**可靠传输**，有流量控制，拥塞控制和**按序交付**的特点。采用三次握手的主要原因：

- 三次握手才可以**阻止重复历史连接的初始化**（主要原因）

  > 两次握手相当于是服务端收到一个SYN报文，它就直接建立了。但是假如它是因为一个历史连接进入的ESTABLISHED，它返回给客户端SYN+ACK会让客户端发现与期待的ACK不一样，于是发出RST。服务端已经发出了一部分数据了。浪费了资源。

  > ​	例如当客户端发送SYN报文（seq＝90）后宕机了，当重启后再次发送SYN报文（seq＝100）注意这里和重传不一样，seq不同。服务端回复ACK（seq＝91）当客户端检测到与期望不匹配后发送RST，服务端释放连接，再次接收到SYN，发送ACK（seq＝101）连接建立成功。而**如果使用二次握手，将没有中间状态给客户端阻止历史连接，导致资源的浪费**（当服务端第一次回复ACK后，就进入了ESTABLISHED状态，此时服务端可能会给历史连接发送数据，白白浪费了服务端的资源）。

- 三次握手才可以同步双方初始序列号

  > 序列号在可靠传输中扮演着重要的作用，凭借序列号实现了，重复包，按序交付等功能。因此需要使用**三次握手来确认双方都正确收到了序列号**

- 三次握手才可以避免资源浪费

  > 四次握手也可以实现可靠传输，但是如果是四次握手，那么服务器在第二次握手时发送SYN，和第三次握手时发送ACK，可以合并为一步，也就是三次握手中的第二次握手。



#### TCP的四次挥手

<img src="./img/tcp-fin-process.JPG" style="zoom: 33%;" />



通常每个方向都需要发送一次 FIN ACK，故称为4次挥手。那么**为什么需要四次而不是三次**，第二次的ACK和FIN不能合并吗？

​	**FIN：表示的语意是说：没有数据要发送了**。也就是说当客户端发送FIN后，表示客户端不在发送数据，而服务端可能还要发送数据，因此先回复ACK，然后发送剩下的数据后，再发一个FIN。



#### 如果FIN报文丢失会发生什么

- 第一个FIN报文丢失。客户端会重传FIN报文`tcp_orphan_retries`次，如果一直收不到回复则直接进入close状态。
- 第二个FIN报文丢失。此时客户端再FIN_WAIT_2阶段
  - 如果是`close()`调用：则会等待`tcp_fin_timeout`后关闭。这个时间通常是60s
  - 如果是`shutdown()`调用：则会死等。



#### 为什么TIME_WAIT状态是2MSL

​	**MSL：报文最大生存时间**，这个时间在linux中定义为30s，也就是说`TIME_WAIT`的时间通常是60s。MSL的定义与TTL有关，**TTL是ip层中的概念，表示最大路由跳数**，数据包每经过一个路由就减1，到0则会被丢弃。通常这个值是64。也就是说linux认为，一个数据包在网络中经过64个路由的时间不会超过30s。**设置成2MSL，是为了预留一次接受数据，并回复数据的时间**。当收到了服务端重发的FIN报文，就会重制TIME_WAIT时间。



#### 为什么需要TIME_WAIT状态

主动断开连接到一方才需要`TIME_WAIT`状态。主要是两个原因：

- 防⽌历史连接中的数据，被后⾯相同四元组的连接错误的接收（**序列号回绕，等待2MSL，能够确保老连接到所有数据消失**），在2MSL的时间后能保证老连接中的数据包都能被丢弃。
- 保证被动关闭连接的一方能够正确关闭（**防止主动关闭方第四次挥手的ACK丢失，无法重传**）

#### TIME_WAIT过多的危害

1. 如果有太多的TCP连接处于TIME_WAIT，它们会占用太多的系统资源：文件描述符、内存资源、CPU资源、线程资源。
2. 端口耗尽的问题，首先是本身端口资源就是有限的，另外：

+ 如果是客户端发起的主动断开，那么过多的TIME_WAIT会使得其他的对相同「目标IP+目标PORT」无法再建立连接
+ 如果是服务端主动断开，并不会特别影响和客户端建立连接，因为客户端IP，PORT不同，于是就可以构造不同的四元组，正常建立连接。但是过多的TIME_WAIT还是会影响系统资源。

#### TIME_WAIT快速回收

当一个 TCP 连接关闭时，主动关闭连接的一方（通常是客户端）会进入 `TIME_WAIT` 状态，这是 TCP 标准的一部分，用于确保延迟的 ACK 确认数据不会被后续连接误解。但是，`TIME_WAIT` 状态会占用系统资源（如文件描述符或端口号）。快速回收机制，是为了在特定情况下，加快 `TIME_WAIT` 资源释放，提升系统效率。

+ net.ipv4.tcp_tw_reuse：如果开启该选项的话，客户端（连接发起方） 在调用 connect() 函数时，如果内核选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态，如果是并且持续时间超过1s，就会重用这个连接，然后就可以正常使用该端口了。所以该选项只适用于连接发起方。
+ tcp_fin_timeout：

​	设置 FIN-WAIT-2 状态下的超时时间，从而间接加速回收。

#### TCP数据分片

<img src="./img/tcp-mtu-mss.JPG" style="zoom:50%;" />

#### TCP 粘包拆包

TCP是面向字节流的协议，它没法区分消息的边界。TCP粘包就是指发送方发送的消息可能会被拼接到一个数据包中发送， 拆包就是指一条消息被拆分成了几个数据包发送出去。

比如程序可能发送多条数据，但由于 TCP 的优化（如 Nagle 算法），操作系统会将多次小数据合并后再发送，增加了**粘包**风险。TCP 可能会根据底层网络链路的最大传输单元（MTU）、数据长度以及缓冲区的大小对发送的数据进行**拆分**。

**解决方法：**

1. **固定消息长度**：每次发送固定长度的数据片段，接收方每次读取固定字节数即可正确解析消息。

2. **使用消息长度前缀**：在每条消息前添加长度标识，告诉接收方当前消息的总长度。接收方首先读取长度标识，然后根据长度读取后续消息。

3. **使用分隔符**：在每条消息结束时添加特殊分隔符，接收方读取数据并根据分隔符解析消息。

4. #### 自定义协议设计：设计一个消息头，每次先把消息头读出来（结合消息长度前缀），消息头中包含了后续消息的长度信息等等。



#### 既然IP层会对数据进行分片为什么还需要MSS

​	首先先明确MSS与MTU。见上图，如果TCP层不分片而是交给IP层分片，这**会导致如果IP层一个分片丢失，那么将会重传IP报文的所有分片**。这是因为，IP层没有可靠传输，当IP层中一个分片丢失，在接收端无法组装为一个完整报文，就不会回复ACK，而导致TCP重传。经过**TCP分片后，重传的单位也是MSS为单位**。





#### 如果客户端的SYN丢包了会发生什么

​	如果客户端发送SYN包后等待一个固定时间没有收到ACK包就会出发重传机制，这个**重传**的次数在linux上记录在`/proc/sys/net/ipv4/tcp_syn_retries`文件下，我的系统默认是6。在每次重传的时，等待时间都会加倍，通常第一次为1s



#### 如果是第二次握手的SYN包丢了会发生什么

​	此时服务端已经收到了客户端发送的SYN包，回复SYNACK包，如果这个包丢失了，那么客户端和服务端均无法收到对应的ACK，因此都会超时重传。客户端的重传次数由：`tcp_syn_retries`决定，服务端的重传次数由：`tcp_synack_retries`决定。



#### 什么是SYN攻击，如何避免SYN攻击

​	SYN攻击是指攻击者在短时间伪造不同IP地址的SYN报文，服务端每收到一个SYN报文就进入SYN_RECV状态，但服务器发送的SYN+ACK报文无法得到未知IP主机的回应，久而久之服务端的**半连接队列**被占满，无法再接受新的连接。

**关于半连接和全连接队列：**

<img src="./img/half-connect-queue.JPG" style="zoom:50%;" />

**避免SYN攻击的方式**

- 增大半连接队列的长度

- 开启`tcp_syncookies`

  开启`tcp_syncookies`就可以在不使用半连接队列的情况下建立连接。具体的工作流程：当半连接队列满后，收到SYN请求会根据算法计算出一个`cookie`值，放到第二次握手的序列号里。服务端在检查到客户端回复的ACK后会检查这个包的合法性，如果合法就放入到accept队列里。

- 减少`SYN+ACk`的重传次数



#### IP头部

TCP需要委托 IP 模块将数据封装成⽹络包发送给通信对象  。在IP协议里需要有源地址IP和目标地址IP。当客户端有多个网卡时，源地址IP应该填写发送数据网卡的IP地址。linux可以使用`route -n`查看路有表。



#### TCP重传机制

常见的重传机制有：

- 超时重传：在消息包发出后，会设置一个定时器，如果一定时间未收到ACK则重传数据包
- 快速重传：收到三次同样的ACK触发快速重传，会在定时器超时之前重传报文。
- SACK（selective ack）：为了解决重传哪些报文问题。SACK会在头部添加SACK选项，并且**将已接收到到数据发送给发送方**，于是发送放就只传丢失的数据。
- D-SACK：与SACK类似但是目的不同，D-SACK通过SACK的方法告诉发送方，这些**数据包被重复接收了**。



#### 滑动窗口

由于TCP需要对每个数据包进行ACK应答，如果采用发送一个等待一个ACK的方式将会导致效率下降。为了解决这个问题TCP引入了窗口的概念，窗⼝⼤⼩：**就是指⽆需等待确认应答，⽽可以继续发送数据的最⼤值**。现在假设窗口大小为3，也就是说发送方可以连续发送3个报文，即使中途回复的ACK丢失了也不影响，因为后续的报文ACK如果被正确收到，就证明中途的所有数据包都到达了。这样被称为**累计应答**。

<img src="./img/accumulate-ack.JPG" style="zoom:50%;" />

注意TCP滑动窗口机制中，每一端（客户端和服务器）都**独立维护两个窗口**：

- **发送窗口（Sender Window）**
- **接收窗口（Receiver Window）**

通过用3个指针来标记这个发送方滑动窗口的四个部分

+ SND.WND: 表示发送滑动窗口的大小
+ SND.UNA(send unacknoleged)，这是一个绝对指针，指向已经发送但是还没有收到ACK确认的第一个字节的序列号
+ SND.NXT: 绝对指针，指向可发送的下一个字节的序列号
+ 一个相对指针，由`SND.UNA + SND.WND`决定，表示了#4区域

可用窗口大小就是`SND.WND-(SND.NXT-SND.UNA)`

接收方的三个部分由两个指针划分:

+ RCV.WND：接收方窗口大小
+ RCV.NXT：绝对指针，指向下一个期望发送来的字节的序列号
+ 一个相对指针，指向#4区域的第一个，由`RCV.NXT + RCV.WND`决定

##### 流量控制

发送发并不会无脑发送数据给接收方。因为如果一股脑发送，超过了接收方的处理能力，反而会造成丢弃，最后进行重发，浪费了资源。

**流量控制就是让发送方根据接收方实际能力控制发送的数据量。**

发送发和接收方的滑动窗口并不是永远不变的，因为这些窗口都是放在操作系统的内存缓冲区，所以会收到操作系统调整。**接收方会通过向发送方自己的窗口大小，使得发送方调整发送速度，是通过ACK报文来通告的。**

当接收方发出**窗口大小为0**的通报时，就会阻止发送方发送数据。直到发送方发出一个窗口非0的ACK报文。但是如果这个报文丢失了，就可能会出现死锁。*也就是，发送方等待接收方的非0窗口通知，接收方也等待发送方的数据。*

所以为了解决这个，每个TCP连接都有一个持续定时器，**只要TCP连接一方收到一个窗口0的通知，就会启动持续计时器。**如果持续计时器超时，就会发送窗口探测(window probe)报文，然后对方确认这个报文的时候会带有自己的窗口大小。

+ 如果仍然是0，重启计时器
+ 如果不是0，死锁局面被打破。

窗口探测一般是3次，超过3次后如果接收窗口大小化石0，TCP连接发送RST报文。

##### 糊涂窗口综合征

这样一个场景，如果接收方实在太忙了，无法处理接受窗口里面的数据，那么窗口大小就会越来越小。假设突然处理了几个字节，然后ACK报文就带着仅有几个字节大小的可用窗口，汇报给了发送方。发送方义无反顾的发送了这几个字节大小的数据。

要知道TCP+IP的头部都有40字节，所以为了传送几个字节而花费这个大开销，不合算。

造成的原因在于：

1. 发送方可以发送几个字节的小数据
2. 接收方可以通报自己只有几个字节大小的小窗口

所以就需要解决上面两个问题

**如何让接收方不可以通报自己只有几个字节大小的小窗口？**

策略如下，当窗口大小小于min(MSS， 缓存空间/2)的时候，就会给发送方说自己的窗口大小为0了，阻止了发送数据。当处理了一些数据后，才打开窗口。

**如果让发送方不发送小数据呢？**

策略如下，使用 *Nagle*算法，思路是延迟处理，需要满足下面两个条件任意一个才能发送数据:

1. 要等到窗口大小>=MSS,并且数据大小>=MSS
2. 收到之前发送数据的ACK回包。

如果两个都不满足，那么发送方一直囤积数据。

> 注意，如果接收方没有满足不允许小窗口通知的话，即使开了Nagle算法也无法避免糊涂窗口，因为假设ACK回复得很快，那么Nagle算法不会拼接很多的数据包，这样就依然有小鼠举报传输。

可以在socket设置`TCP_NODELAY`来开关闭这个算法，

#### 拥塞控制 (防止发送过多数据导致网络拥塞)

流量控制是发送端与接收端之间的事情，而拥塞控制是整个网络之间的事情。当TCP发现网络之间出现拥塞，他是无私的，会资源牺牲降低发送的数据量。

为了在发送方调节要发送的数据量，有一个 **拥塞窗口(cwnd)**的概念。它动态反应了网络的拥塞程度。

发送窗口的大小swnd=min(cwnd,rwnd)

拥塞窗口的简单改变原则就是：

+ 如果网络没出现拥塞，就增大cwnd
+ 如果出现拥塞就减少cwnd

衡量是否出现拥塞的标准就是，*发送方没有在规定时间内收到ACK报文，也就是发送了超时重传就会认为发生了拥塞*

拥塞控制主要有四个算法

**慢启动**

刚建立TCP连接，首先是一个慢启动过程，它有一个较小的初始cwnd值，然后接下来每收到一个ACK就增大1个cwnd单位。比如`cwnd=1`，然后收到ACK后，`cwnd=2`，接下来就发送两个TCP段，收到两个ACK ,`cwnd=4`。所以慢启动是一个指数增长的过程。

**拥塞避免**

它当然不可能是无限增长的，当`cwnd=sshresh`（慢启动门限）后，就进入线性增长的区间，接下来每收到一个ACK回复就增加`1/cwnd`

**拥塞发生**

当发送拥塞（数据包重传）的时候，根据重传机制的不同有不同的拥塞控制方法

1. 对于超时重传

超时重传认为网络已经比较阻塞了，就会直接把`sshresh=cwnd/2, cwnd=init value`，然后就会回到慢启动

2. 对于快速重传

​	当收到3个重复ACK的时候，实际上等不到超时重传发生，就会立刻进行快速重传。如果发送快速重传我们认为网络还没有那么拥塞，比较能收到3个ACK嘛，于是`cwnd=cwnd/2`,`sshresh=cwnd`，进入快速回复算法。

​	*快速回复算法*

+ cwnd=sshresh+3
+ 重传丢失的数据包
+ 如果还是收到重复的ACK，那么cwnd+1
+ 如果收到新的数据ACK,cwnd设置为刚进入快速回复时候的sshresh，进入拥塞避免阶段（也就是线性增长）

#### PAWS

PAWS算法是为了解决序列号回绕现象的。

**(1) TCP 序列号是有限的**

- TCP 的 **序列号（Sequence Number, SEQ）** 是 **32 位** 的。
- 取值范围：`0` ~ `2^32 - 1`（`0 ~ 4,294,967,295`）。
- 如果 TCP 连接**长时间持续发送数据**，序列号会**回绕**（即重新变成 `0`）。
- 这种情况称为 **序列号回绕（Sequence Number Wraparound, SNW）**。

**(2) 高速网络会加速序列号回绕**

- 在 **低速网络**，数据包传输时间长，旧数据包很难滞留在网络中，回绕风险较小。
- 在 **高速网络**（如 10 Gbps+），TCP 可以在**几秒钟内**用完整个 32 位序列号空间。
- 如果旧数据包在回绕发生后才被网络延迟送达，TCP 可能会误认为**它是新数据包**，从而导致数据错乱！

**(3) 解决方案：时间戳**

PAWS **不使用序列号来区分新旧数据包**，而是**利用 TCP 时间戳（Timestamp）来判断数据包是否过时**。

**TCP 时间戳（Timestamp）选项**是在 TCP 头部的**可选字段**（TCP Options）中定义的。它包含两个值：

- **TSval（时间戳值）**：发送方的当前时间戳。
- **TSecr（时间戳回显值）**：接收方收到的数据包时的时间戳。

当 TCP 连接收到一个数据包时：

1. 检查时间戳（TSval）是否比最近收到的 TSval 更大
   - ✅ **如果是更大的时间戳（新数据包），接受数据包**。
   - ❌ **如果时间戳是旧的（回绕前的数据包），丢弃！**
2. **这样，即使序列号回绕，PAWS 仍然可以正确区分新旧数据包**。



## 交换机

### 为什么交换机叫二层网络设备

交换机的设计是将⽹络包原样转发到⽬的地。**交换机⼯作在 MAC层**，也称为⼆层⽹络设备  



### 交换机的工作原理

交换机接收所有的包，并放到缓存区中，接下来查询这个包的接收⽅ MAC 地址是否已经在 MAC 地址表中有记录了  ，**交换机的 MAC 地址表**主要包含两个信息  ：

1. 设备的MAC地址
2. 该设备连在交换机的哪个端口上

然后根据这些信息转发包。**如果在MAC地址表中没有找到接受设备：交换机会把这个包发送到除源端口的所有端口上**，发送了包之后⽬标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写⼊ MAC 地址表，下次也就不需要把包发到所有端⼝了  。

### 路由器和交换机的区别

- 路由器是基于IP设计的，是三层网络设备，每个端口都有MAC和IP地址。
- 交换机是基于以太网设计的，是二层网络设备，交换机端口不具备MAC地址。



## 网络分层模型

<img src="./img/osi-network-level.JPG" style="zoom:50%;" />



网络分层模型是网络通信的基础，其中最著名的两个模型是OSI（开放系统互连）模型和TCP/IP模型。

OSI模型由七层组成，从下到上分别是：

1. **物理层**：这一层处理与物理介质相关的细节，如电压、电缆、光纤、接口、传输速率等。它的主要任务是定义物理设备如何传输数据。

2. **数据链路层**：这一层负责节点之间的数据传输，如以太网（Ethernet）、Wi-Fi。它提供了错误检测和控制，确保数据的正确传输。

3. **网络层**：这一层负责数据包的发送和路由，包括IP地址处理和路由选择。

4. **传输层**：这一层负责提供端到端的通信能力。在这一层，有两个非常重要的协议：TCP（传输控制协议）和UDP（用户数据报协议）。

5. **会话层**：这一层负责建立、管理和终止会话。会话是应用程序之间的对话，包括请求和响应。

6. **表示层**：这一层处理数据的表示方式，包括数据的加密、解密、压缩、解压缩等。

7. **应用层**：这一层为应用软件提供了网络服务。应用程序如HTTP、FTP、SMTP等都在这一层工作。

TCP/IP模型是另一个重要的网络通信模型，它只有四层：

1. **网络接口层**：这一层对应OSI模型的物理层和数据链路层，处理所有硬件级的数据传输。

2. **网络层**：这一层对应OSI模型的网络层，处理数据包的发送和路由。

3. **传输层**：这一层对应OSI模型的传输层，处理端到端的通信。

4. **应用层**：这一层对应OSI模型的会话层、表示层和应用层，处理所有和应用有关的协议和其他特定的数据。



## HTTP

### 常见HTTP状态码

![](./img/http-status-code.JPG)

#### 2XX

- [200 OK] 是最常⻅的成功状态码，表示⼀切正常。如果是⾮ HEAD 请求，服务器返回的响应头都会有 body 数据。
- [204 No Content] 与 200 类似，但是Body中数据为空
- [206 Parial Content] 是应⽤于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，⽽是其中的⼀部分，也是服务器处理成功的状态。

#### 3XX

- [**301** Move Permanently] 表示永**久重定向**，说明请求的资源已经不存在了，需改⽤新的 URL 再次访问。
- [**304** Not Modified] 告诉客户端可以**继续使用缓存资源**



#### 4XX

- [**400** Bad Request] 表示客户端**请求的报⽂有错误**，但只是个笼统的错误。 
- [**403** Forbidden] 表示**服务器禁⽌访问资源**，并不是客户端的请求出错 



#### 5XX

- [500 Internal Server Error] 与 400 类型，是个笼统通⽤的错误码，服务器发⽣了什么错误，我们并不知道 
- [501 Not Implemented] 表示客户端请求的功能还未实现
- [**502** Bad Gateway] 通常是服务器作为⽹关或代理时返回的错误码，**表示服务器⾃身⼯作正常，访问后端服务器发⽣了错误** 
- [**503** Service Unavailable] 表示**服务器当前很忙，暂时⽆法响应客户端**，类似“⽹络服务正忙，请稍后重试”的意思 .



### HTTP缓存技术

HTTP缓存技术分为两点：**强制缓存**和**协商缓存**。

#### 强制缓存

​	强缓存指的是只要浏览器判断缓存没有过期，则直接使⽤浏览器的本地缓存，决定是否使⽤缓存的**主动性在于浏览器这边**。

强制缓存的实现通过两个头：

- `Cache-Control`:  指定一个相对时间
- `Expires`:  绝对时间

在生产中常用第一个。如果响应头中同时出现了上述两个头，**第一个优先级更高**。强制缓存的工作原理：

1. 当浏览器发出请求后，服务器会返回响应，并在响应头中加入Cache-Control和/或Expires字段。
2. 浏览器收到响应后，会将响应数据和响应头一起缓存下来。
3. 下次浏览器再请求这个资源时，会先检查本地缓存。如果本地缓存中有这个资源，并且没有超过`max-age`定义的有效期或者系统时间小于`Expires`定义的过期时间，那么浏览器就直接使用缓存的资源，而不会向服务器发送请求。这个过程是在浏览器本地完成的，所以速度非常快



#### 协商缓存

在浏览器使⽤开发者⼯具的时候，你可能会看到过某些请求的**响应码是 304 ，这个是告诉浏览器可以使⽤本地缓存的资源**。协商缓存的实现方式：

第一种：通过请求头部的：`If-Modified-Since` 和 响应头部的：`Last-Modified`。

第二种：通过请求头部的：`If-None-Match` 和响应头部的：`ETag` 字段。实现原理，**ETag唯一标识响应资源**（ETag的值一般是对文件内容进行哈希计算得到的），当客户端请求的 `If-None-Match`与`ETag`不符时返回200，符合时返回304。

如果同时存在两种，这**ETag的优先级更高**。



### HTTP特性

HTTP常见版本有：HTTP/1.1，HTTP/2.0，HTTP/3.0

#### HTTP/1.1

优点：

- 支持长链接

- 支持了管道网络传输，只要第一个请求发出去了，不必等待回来就可以发第二个请求出去。但是这些连续的请求在服务端，必须等到第一个到来的请求被响应后才能处理后续的请求。也就是解决了请求队头阻塞，但是没有解决响应队头阻塞。

  

缺点：

- 无状态
- 明文传输



#### HTTP/2.0

HTTP/2.0基于HTTPS，因此本身就是安全的。相对于1.1的改进：

1. 头部压缩：通过HPACk算法，将相似的头部压缩为1个
2. **二进制格式**：数据和头部均采用二进制传输
3. **并发传输**：Stream概念，
4. **服务器主动推送资源**：服务器可以主动向客户端建立Stream（偶数序号）



#### HTTP/3.0

主要改进：将HTTP的底层换成了**UDP协议**（基于QUIC）

## GET与POST

**GET 的语义是从服务器获取指定的资源**，GET 请求的参数位置一般是写在 URL 中。

**POST 的语义是根据请求负荷（报文body）对指定的资源做出处理**，POST 请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。

## HTTPS

### HTTP与HTTPS的区别

- **安全性**：HTTP是超文本传输协议，明文传输，存在安全风险。HTTPS通过在**TCP和HTTP层之间插入SSL/TLS安全协议**使得报文能够安全传输。
- **连接建立**：HTTP只需要执行TCP三次握手，HTTPS在TCP三次握手后还需要执行SSL/TLS握手。
- **默认端口不同**：HTTP默认端口80，HTTPS默认端口443
- HTTPS需要向CA（证书权威机构）申请数字证书来保证服务器是可信的。



### HTTPS的原理

HTTPS通过加入SSL/TLS协议实现了：

- **信息加密**：交互信息无法被窃取
- **校验机制**：无法篡改通讯内容
- **身份证书**：证明你访问的“淘宝”是真的“淘宝”

**HTTPS是如何实现上面的功能的**？

- 混合加密

- 摘要算法

- 将服务器公钥放入“**数字证书**”（数字签名）

  **关于证书是如何确保可靠的说明**（重要，感觉很多公司都问了）：

  - **数字签名**：**证书包含CA的数字签名**。**数字签名是使用CA的私钥生成的，客户端可以使用CA的公钥验证签名的真实性**。
  - **证书链**：证书通常是由多个证书组成的链条（证书链），每个证书都由上一级证书签名，直到根证书。根证书是自签名的，并预装在操作系统或浏览器中。客户端通过验证整个证书链来确保证书的合法性。

#### 混合加密

混合加密保证了信息的机密性，解决窃听的风险。

- 在通讯开始之前，使用非对称加密交换会话密钥。

> 1. 客户端生成一个随机的对称加密密钥（称为“会话密钥”）
> 2. 使用服务器的公钥加密这个随机密钥，然后发送给服务器
> 3. 一旦服务器解密了客户端发送的随机密钥（即会话密钥），双方就可以使用这个密钥进行后续通信.

- 通讯开始后使用对称加密

非对称加密慢，但是能做到安全的密钥交换；对称加密快但是无法做到安全的密钥交换。

#### 摘要算法

摘要算法防止传输的能内容不被篡改

摘要算法（哈希函数）来计算出内容的哈希值，也就是内容的「指纹」，这个哈希值是唯⼀的，且⽆法通过哈希值推导出内容。

通过哈希算法可以确保内容不会被篡改， 但是**并不能保证「内容 + 哈希值」不会被中间⼈替换**。为了解决上述问题，我们需要使用数字签名算法（**非对称加密，使用私钥加密哈希值，公钥解密**）



#### 数字证书

摘要算法中使用到的数字签名，需要服务器的公钥，为了防止这个公钥被伪造，需要将这个公钥存储到第三方机构。



### HTTPS连接建立

SSL/TLS协议基本流程

- 客户端向索要并验证服务器公钥
- 双方协商产生会话密钥
- 双方采用会话密钥进行通讯

SSL的握手阶段一共**4次通讯**，使⽤不同的密钥交换 算法。 握⼿流程也会不⼀样的，现在常⽤的密钥交换算法有两种：  RSA算法 和  ECDHE算法。

**先三次握手**

#### 基于RSA加密方式的连接建立流程

1. Client Hello

   用户发送：支持的**TLS版本**，使用的**加密算法**，一个客户端生成的**随机数**

2. Server Hello

   服务端响应：使用的**TLS版本**，使用的**加密算法**，一份服务端生成的**随机数**，**服务器的数字证书**

3. Client Response

   首先，从浏览器或者操作系统中的**CA公钥确认证书真伪**，然后**提取服务器公钥**，然后使⽤它加密报⽂，然后向服务器发送：一个随机数（被公钥加密），加密算法变更通知（表示随后的信息都将⽤「会话秘钥」加密通信。），客户端握手结束

4. Server Response

   获得客户端发送的公钥后，生成本次会话的密钥。然后回复：加密算法变更通知，服务端握手结束

> 关于各个阶段随机数的作用：首先在完成1，2步握手后，服务端和客户端都会有两个随机数分别是：`ClientHello.random`和`ServerHello.random` 然后第三步握手时，客户端通过加密传输一个新的随机数称为：`PreMaster Secret`，随后服务器和客户端通过上面三个随机数独立计算出本次会话的对称密钥。**这些随机数的存在是为了确保每次会话都有一个独一无二的密钥**，**防止重放攻击**，因为攻击者即使能够记录下所有的网络传输，也无法在没有正确的随机数和PreMaster Secret的情况下重建会话密钥



#### 基于ECDHE的加密方式连接建立流程

之所以需要ECDHE是因为基于RSA的加密方式存在前向安全问题，也就是说当服务器私钥泄露，那么之前截获的报文就可以被解密了。

`ECDHE`算法的核心是：`DH`算法（一种**非对称加密算法**，因此可以用于密钥交换）DH算法的基本思想是离散对数，`DHE`算法对DH的改进主要是：**每次会话都产生一个临时的私钥和公钥**，`ECDHE`的改进：不在使用离散对数改**使用椭圆曲线特性**。

以下是`ECDHE`的基本流程：

1. **密钥对生成**：通信双方各自生成一对临时的公钥和私钥。这是在选定的椭圆曲线上随机选择一个点，并将它乘以椭圆曲线的一个固定参数来完成的。生成的公钥是椭圆曲线上的一个点，而私钥是用于生成公钥的随机数。

2. **公钥交换**：通信双方互换公钥。这通常通过不安全的通道进行，因此公钥可能被攻击者截获。但是，由于椭圆曲线离散对数问题的困难性，攻击者无法从公钥推算出私钥。

3. **会话密钥计算**：通信双方各自使用对方的公钥和自己的私钥计算出同一个会话密钥。这是通过将对方的公钥乘以自己的私钥来完成的。由于椭圆曲线的性质，这将得到椭圆曲线上的同一个点，这个点可以用作会话密钥。

4. **通信**：通信双方使用计算出的会话密钥进行通信。由于攻击者无法从公钥推算出私钥，因此他也无法计算出会话密钥，从而无法解密通信内容。

5. **密钥销毁**：通信结束后，通信双方销毁临时的公钥和私钥，以及计算出的会话密钥。这样，即使攻击者在通信结束后获得了密钥，他也无法解密通信内容，因为使用的密钥已经被销毁。这就是ECDHE的前向安全性。



## WebSocket

WebSocket 是一种**网络通信协议**，它提供了**全双工（full-duplex）通信通道**，这意味着服务器和客户端可以同时发送和接收信息。

​	在传统的 HTTP 协议中，客户端（通常是浏览器）发送请求到服务器，然后服务器回应这个请求。这种通信方式只能由客户端发起。但是在某些情况下，服务器可能需要在没有客户端请求的情况下向客户端发送数据。例如，在实时聊天应用、游戏、实时报价等场景中，服务器需要主动向客户端推送信息。

在 WebSocket 协议中，一旦建立了 WebSocket 连接，服务器就可以主动向客户端发送数据，而不需要等待客户端的请求。同时，客户端也可以主动向服务器发送数据，而不需要等待服务器的响应。这就是所谓的全双工通信。

WebSocket 协议由两部分组成：握手和数据传输。

1. **握手**：首先，客户端会向服务器发送一个**特殊的 HTTP 请求**，请求升级到 WebSocket。如果服务器支持 WebSocket，并且同意升级，那么服务器会发送一个特殊的 HTTP 响应，确认升级。一旦握手成功，HTTP 连接就会升级为 WebSocket 连接，然后就可以开始数据传输。

2. **数据传输**：在 WebSocket 连接中，数据以消息为单位进行传输。每个消息都可以包含任意数量的数据，并且可以在任何方向上发送。消息可以包含文本数据或二进制数据。

WebSocket 协议非常适合需要实时数据交换的应用，例如实时聊天、游戏、实时报价等。



## IP

### ICMP

ping是基于`ICMP`协议工作的，叫做「**Internet Control Message Protocol**」。

网络包在复杂网络环境中传输的时候会遇到各种的问题，通过ICMP协议传出的消息来得到报告。

当IP通信中，某个IP包因为某种原因没能达到目标地址，那么这个具体原因是由ICMP负责沟通的。

ICMP分为了，查询报文与差错报文。`ping`就是查询报文的应用，而`traceroute`就是差错报文的应用。

### traceroute的使用

+ `traceroute` 可以显示数据包经过的网络路径和所涉及的中间路由器或设备，帮助理解流量流经的网络拓扑。