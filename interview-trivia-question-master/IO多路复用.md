假如我们要设计一个网络服务器，它会面临很多客户端的连接请求，有什么设计思路？

第一种显而易见的，就是每有一个连接请求就建立一个线程来单独处理。这样的方法可能会创建很多的线程，而线程之间的切换涉及了上下文切换，对CPU的代价较高。

## I/O多路复用

I/O多路复用的思想和CPU的并发多个进程很像。既然为每个连接分配一个线程/进程的方式不适合，那么如果我们只用一个进程来处理很多个请求，把对处理每个时间的控制在1ms，那么1分钟就可以处理上千个请求。看起来就像多个请求都复用了一个进程。

### select/poll

select实现多路复用的方式是，把所有已经连接的socket都放入一个 **文件描述符**集合，然后调用`select`方法把这个文件描述集拷贝到内核中。内核来检查是否有网络事件产生，检查的方式就是 **直接遍历文件描述符集合**。当检查到有事件产生，就把这个socket标为可读或可写，然后再把这个文件描述符拷贝回用户态。用户态还需要 遍历这个文件描述符集合找到可读可写的socket。

select中，使用的是固定长度的BitsMap表示文件描述符集合，具体长度由`FD_SETSIZE`决定，默认是1024.

poll不再使用BitsMap表示文件描述符集合，而是使用动态数组以链表来组织。

**select/poll都是使用「线性结构」存储进程关注的socket集合，因此都需要遍历来找到可读或可写的socket，复杂度都是O(n)**

### epoll

epoll的大概用法是这样的：`epoll_create`创建一个epoll对象`epfd`，然后通过`epoll_ctl`把需要监视的socket放入`epfd`中，然后调用`epoll_wait`等待数据

epoll相比select有很多改进

+ epoll内核里面使用红黑树来跟踪所有待检测的文件描述字，`epoll_ctl`就是把需要监控的socket放入epoll_ctl()中。红黑树的增删查改时间一般是O(logn)。而且相比于`select/poll`它们在内核中没有维护一个像红黑树这样保存所有待检测socket的数据结构，所以它们每次都需要复制整个socket集合给内核。而epoll中在内核维护了红黑树，于是每次只需要传入一个待检测的socket。
+ epoll是 *事件驱动*的，内核里面维护了一个链表来记录就绪事件。当某个socket有事件发生，就会通过 *回调函数*内核将其加入到这个就绪事件列表中。用户调用`epoll_wait`只会返回有事件发生的文件描述个数，而不用和`selec/poll`一样去轮询整个socket集合。

epoll能解决C10K问题。

**边缘触发和水平触发**

epoll支持两种事件触发模式，分别是边缘触发（ET）和水平触发（LT）

+ 边缘触发：当被监控的socket有可读事件发生的时候，服务器端只会从epoll_wait苏醒一次，即使进程没有调用read从内核去读，也只会苏醒一次。因此要抱着一次性将内核缓冲区的数据读取完。
+ 水平触发：当被监控的socket有可读事件发生，服务器会不断从epoll_wait中苏醒。直到内核缓冲区数据被read函数读完才结束。

边缘触发一般会搭配非阻塞I/O搭配。

`select/poll`只有水平触发模式，epoll默认是水平触发。