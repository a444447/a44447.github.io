---
title: "Gnn_basic"
date: 2023-08-10T19:29:11+08:00
categories: [深度学习入门, cs231n]
draft: true
---

## 引入

在机器学习问题中，有两种建模方法：「generative models（生成模型）」和「discriminative models（判别模型）」。就我目前的理解来说，生成模型是要求出联合概率分布$P(x,y)$，然后通过贝叶斯公式转换（$P(y|x) = \frac{P(x|y)P(y))}{P(x)}$），求出$P(y|x)$。而判别模型则是从过去数据中，直接学习到一个$P(y|x)$，或者说是$f(x)$，它走的方式是input --> label，这与我们的线性回归很相似。

## GAN介绍

GAN在很多地方都可以应用，比如生成图片，重构图片，风格迁移、高分辨率等等。GAN网络有两个核心的结构，一个叫做「生成器(generator)」，一个叫做「判别器(discriminator)」，在训练过程中，这两者都需要训练。GAN的思路是这样的：*假如我们的原始数据都是属于$P_{data}$分布，判别器$D$的作用就是对于从$P_{data}$中sample出来的数据，它会判别为真(true or 1)；而我们的生成器$G$就是会生成数据，并试图让这些数据「欺骗」判别器；而判别器$D$会不断努力识别出「假数据」——因此GAN的过程就像是G与D的不断博弈升级*。



### 极大似然找相近分布

首先，再次声明一下我们后面用到的符号的含义：

+ $P(x)$表示的是分布中采样到样本x的概率，试想如果我们知道该分布中每个样本的采样概率，那么这个分布也就可以以这种形式表示出来了。
+ $P(x;\theta)$表示的是一个 **确定的分布**。其中$\theta$就是表示该分布的参数，该分布的具体形式确定了（比如 $P(x;\theta)$可以是高斯分布， $\theta$ 就是高斯分布的均值 $\mu$ 和方差 $\sigma$

---

现在，明确我们的目的，我们希望GAN能够学习到train data的分布，从而能够sample出新的数据。因此我们的目标归纳为:

+ 我们拥有一个train data的分布$P_{data}(x)$
+ Generator生成的分布为$P_G(x;\theta)$
+ 我们通过最大似然估计，找到一个$\theta ^*$，使得$P_G(x;\theta ^*)$与$P_{data}(x)$有近似的分布（$P_{data}(x)$可能很复杂，我们几乎无法找到表示的方式，因此希望用另一个分布能够最大化的表达它）。

所以我们的极大似然估计方案是这样的:

1. 首先需要从$P_{data}(x)$中sample出一系列样本${x^1,x^2,...,x^m}$

2. 似然函数$L=\prod_{i=1}^m P_G(x^i;\theta)$
3. 计算似然函数，找到最大的$\theta=arg\underset{\theta}{max}L$

{{<notice notice-note>}}

之所以$\prod_{i=1}^m P_G(x^i;\theta)$可以用作似然函数，是因为我们认为，如果我们从$P_{data}$中sample出来的$x^1,x^2...$在$P_G$分布中出现的概率越高，那么这两个分布也越相似，毕竟如果概率完全相同那么，sample出来的样本也足够多，就能够近似认为它们是同一个东西了。

{{</notice>}}

![image-20230814112535338](https://obsdian-1304266993.cos.ap-chongqing.myqcloud.com/202308141125402.png)

最后式子可以化简为
$$
arg \underset {\theta}{max}KL(P||Q)(P_{data}(x)||P_G(x;\theta))
$$

> KL散度是衡量两个分布的差异的: $KL(P||Q) = \int_x p(x)(logp(x) - logq(x))$

因此，我们想做的实际上就是找到一个$\theta$使得KL散度足够低，这样分布之间也足够接近。

### GAN流程

我们上面提到极大似然的时候已经说过，GAN的主要目的就是想用一个生成器，生成器G的分布$P_G(x; \theta)$和原始数据的分布$P_{data}(x)$尽可能接近，从而使得从$P_G$中生成数据就可以看作是从$P_{data}$中生成数据。

要找到合适的参数$\theta$是很困难的，比如如果我们只用高斯分布的话，很难去接近那些复杂的真实分布。因此用神经网络的方法来实现。其整体pipline流程图如下：

![img](https://pic1.zhimg.com/80/v2-7f9c475f7ed92773caa7ff3a9f50a118_1440w.webp)

可以看到，整体的流程就是:

1. 从简单的先验分布$P_{prior}$中采样了$z$作为输入，然后$G(z) = x$。通过这样的方式就构建了$P_G(x;\theta)$。分布由神经网络G决定，由$\theta$定义网络，通过输入$z$来采样x。
2. 通过比较两分布之间的loss,来判断两个分布的差异情况，从而调整$\theta$,因此这个loss需要好好设计，要能够反正两个分布的距离情况。

---

如果GAN结构只有一个生成器G，那么我们很难用极大似然估计来衡量两者之间的差异，因为$P_G(x;\theta)$的计算是很复杂的，其公式如下:
$$
P_G(x;\theta) = \int_x P_{prior}(z)I[G(z;\theta)=x]dz
$$
**上面的公式意思就是，$P_G(x;\theta)$**的值是所有能使得$G(z;\theta)=x$成立的$z$出现的概率之和。

---



既然用我们上面的极大似然估计公式很难，那么在GAN的结构中就引入了一个判别器D，它的作用就是对于$P_{data}$中的样本给出「真值」，而对于$P_G$生成的样本识别出「假值」。所以现在总结GAN中生成器与判别器的作用就是:

对于生成器 G：

1. G 是一个函数，输入 $z$ ~ $P_{prior}$ ，输出 $x$∼$P_G$ （上面已经介绍了）

对于判别器 D :

1. D是一个函数，输入 $x$∼$P_G$ ，输出一个scalar



最终的优化目标就是:$G^*=arg \ \underset{G}{min} \ \underset{D}{max} V(G,D)$

其中$V(G,D) = E_{x-P_{data}}[logD(x)] + E_{x-P_{G}}[log(1-D(x))]$

解释一下就是: maxV(G,D)表示的是两个分布之间的差异，min maxV(G,D就是要最小化它们之间的差异,我们希望能够得到$G*$使得max(V,D)成立。那么为什么$arg \ \underset{D}{max}V(G,D)$能表示差异呢？

> https://zhuanlan.zhihu.com/p/266677860可以看下这个



---

### 具体训练算法

首先初始化$\theta_D$和$\theta_G$

对于每一轮训练，按照以下执行

![image-20230814135233142](https://obsdian-1304266993.cos.ap-chongqing.myqcloud.com/202308141352193.png)

> 实际上可以这样的理解，$logD(x)$就是在求判别器D对于真实数据的反应，因此我们希望判别器给它们判为「真值」，也就是越大越好。而logD(G(z))表示生成的假数据，判别器应该尽力判断它为假，因此给它的值越小越好，而为了统一是最大化表示性能好，上面的公式是用1去减去。

![image-20230814135332908](https://obsdian-1304266993.cos.ap-chongqing.myqcloud.com/202308141353953.png)
