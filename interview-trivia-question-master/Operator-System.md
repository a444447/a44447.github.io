# 操作系统与计算机组成

# 硬件相关

### 冯诺依曼模型

定义计算机的基本结构为5个部分：

- **中央处理器**

  - **位宽**：32/64 位CPU最主要的区别在于一次能计算多少个字节数据（**位宽**）
  - 寄存器种类
    - 通用寄存器
    - 程序计数器
    - 指令寄存器

- **内存**

- **输入设备**

- **输出设备**

- **总线**：用于CPU和内存以及其它设备之间的通信，总线可分为3种

  - 地址总线

  - 数据总线

  - 控制总线

    总线位宽：如果想要 CPU 操作 4G 的内存，那么就需要 32 条地址总线（通常要求CPU位宽不要小于总线位宽）

### 关于32位与64位

 64位相比32位CPU的优势主要体现在两个方面：

- 64位CPU可以一次性计算超过32位的数字
- 64位CPU可以寻址更大的内存空间

64位和32位软件，实际上代表指令是64位还是32位的：

- 如果32位指令在64位机器上执行，需要一套兼容机制，但是反过来不好实现。因为32位寄存器存不下64位的指令

**总之：硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽**。



## CPU执行程序的过程

1. CPU读取 **程序计数器** 的值（内存地址），然后从内存地址中读取具体的指令存入 **指令寄存器**。
2. 译码
3. 执行
4. 程序计数器 自增（自增大小由位宽决定。）

读取指令、到执⾏、再到下⼀条指令，这个过程会不断循环，直到程序执⾏结束，这个不断循环的过程被称为 CPU 的**指令周期**。通常一个指令周期包含四个阶段（四级流水线）取指，译码，执行，会写。



## 存储器结构

存储器根据速度的快慢，由快到慢可以分为这么几个级别：

1. 寄存器
2. L1－L2－L3 Cache：使用的SRAM（静态随机存储，断电后数据消失）
3. 内存：使用DRAM（通过电容存储数据，需要动态刷新）
4. SSD/HDD 硬盘

> 其中1，2都在CPU内部

![](img/L1-L3Cache.JPG)



## 如何写出让CPU跑得更快的代码

要想写出让CPU跑得更快的代码，关键就是要让CPU的Cache命中率提高，CPU中的Cache通常分为指令Cache和数据Cache。下面就分别提高两个Cache的命中率讨论



### 提高数据缓存命中率

遍历数组的情况时，**按照内存布局顺序访问**，将可以有效的利⽤ CPU Cache 带来的好处。



### 提高指令缓存命中率

关键是让 CPU分支预测器 预测准确。例如：以下代码

```c++
// Function to filter vector
std::vector<int> filterVector(const std::vector<int>& input) {
    std::vector<int> result;
    for (int i = 0; i < input.size(); i++) {
        if (input[i] > 50) {
            result.push_back(input[i]);
        }
    }
    return result;
}
```

加入input中的数据是乱序的，那么我们是先排序再调用`filterVector` 还是直接调用，更快呢？当数组中的元素是随机的，分⽀预测就⽆法有效⼯作，⽽当数组元素都是是顺序的，分⽀预测器会动态地根据历史命中数据对未来进⾏预测，这样命中率就会很⾼。



### 提升多核CPU的缓存命中率

​	现代CPU都是多核心的，进程可能在多个不同的CPU核心来回切换执行，这对CPU Cache不是有利的。**我们可以把线程绑定在某⼀个 CPU 核⼼上，这样性能可以得到⾮常可观的提升**。



## 多核CPU缓存一致性

在多核环境下，如果一个核心将数据写入Cache之后，内存与Cache相对应的数据将会不同，这种情况下就需要**将Cache中的数据同步到内存**里。写入Cache的时机：

- 写直达：把数据同时写入内存和Cache中
- 写回：当发生写操作时，新的数据仅仅被写入Cache Block里，只有当修改过的Cache被替换时才需要写到内存中。

### 缓存一致性问题

​	由于L1/L2 Cache是多个核心各自独有的，那么会带来多个核心的缓存一致性问题。解决缓存一致性问题的两种机制：

- 某个CPU核心里的Cache数据更新时，必须要传播到其他核心的Cache，这个称为**写传播**。
- 某个CPU核心里对数据的操作顺序，必须在其它核心看起来是一样的。这个称为**事务的串行化**

两种机制的实现：

- 总线嗅探：用于**实现写传播**。总线嗅探的工作机制：当 A 号 CPU 核⼼修改了 L1 Cache 中 i 变量的值，通过总线把这个事件⼴播通知给其他所有的核⼼，然后**每个 CPU 核⼼都会监听总线上的⼴播事件**，并检查是否有相同的数据在⾃⼰的 L1 Cache ⾥⾯，如果 B 号 CPU 核⼼的 L1 Cache 中有该数据，那么也需要把该数据更新到⾃⼰的 L1 Cache。

  > 总线嗅探只是保证了写传播，但是没有实现事务串行化。

- MESI 协议。该协议是由四个单词的缩写组成：

  - Modified：已修改，就是脏标记，代表该Cache上的数据已经被更新过，但还没有写入内存。
  - Exclusive：独占，数据是干净的，且**数据只存储在一个CPU核心的Cache里**。这个时候可以自由的写入数据，而不需要通知其它CPU。如果其它核心要读取相同数据到自己的Cache，**独占状态下的数据就会变成共享状态**。
  - Shared：共享，数据是干净的，且**多个CPU核心的Cache里都有**。这个时候要更新Cache数据时，需要**先向其它CPU核心广播一个请求，要求把其它核心的Cache中对应的Cache line标记为无效状态**，然后再更新当前Cache里数据。
  - Ivalidated：已失效，表示这个Cache Block里对数据已经失效，不应该读取该状态的数据。

  

### Cache中的伪共享问题

​	CPU 从内存中读取数据到 Cache 的时候，并不是⼀个字节⼀个字节读取，⽽是⼀块⼀块的⽅式来读取数据的，这⼀块⼀块的数据被称为 **CPU Line（缓存⾏）**。那么对于数组元素的加载，CPU就会加载数组里面连续多个数据到Cache里，这样顺序访问数组元素时，Cache命中率就会很高。**但是，在我们不使用数组，而是单独使用变量时，则会存在Cache伪共享问题，伪共享问题是一个性能杀手，我们应该规避它**。

​	现在假设有⼀个双核⼼的 CPU，这**两个 CPU 核⼼并⾏运⾏着两个不同的线程，它们同时从内存中读取两个不同的数据**，分别是类型为 long 的变量 A 和 B，这个两个数据的地址在物理内存上是连续的，如果Cahce Line 的⼤⼩是 64 字节，并且变量 A 在 Cahce Line 的开头位置，那么这**两个数据是位于同⼀个**
**Cache Line 中**：

![](img/cache-fake-share.png)

现在我们结合MESI协议，来讨论如果两个线程分别修改A和B变量会导致什么？

1. 首先假设1号核心先从内存读取数据，那么它将一个Cache line大小的数据读入自己的Cache，并将该Cache块标记为 **独占**。
2. 然后2号核心从内存读取数据，由于已经存在一份在1号核心的Cache中，所以2号核心和1号核心将读取的Cache块标记为 **共享**。
3. 然后1号核心修改A，由于此时Cache块为share状态，所以1号核心先让2号核心的Cache变为：**已失效** 状态，然后修改A数据，将自己的核心Cache块转为 **已修改** 状态。
4. 之后2号核心要修改B，由于Cache块已失效，另外1号核心的Cache也有相同数据，且状态为已修改，所以**需要先把1号核心对应的Cache写回到内存，然后2号核心再从内存读取，最后把2号核心的Cache标记为已修改，1号核心的标记为已失效**。

这种因为多个线程同时读写一个Cache line的不同变量时，而导致Cache失效的现象称为：伪共享（False Sharing）。



### 避免伪共享的方法

根据上面提到的伪共享原理，避免伪共享，就是避免多个线程修改的数据位于同一个Cache line中。在实际项目中，我们可以通过`__cacheline_aligned_in_smp` 宏定义，用于解决伪共享问题。该宏定义的原理是将变量的地址设置为Cache line大小的对齐。



## 完全公平调度算法（CFS）

​	这个算法的理念是让分配给每个任务的CPU时间是一样的。于是它为每个任务安排一个虚拟运行时间`vruntime`。在CFS算法调度的时候，会**优先选择 vruntime 少的任务**，以保证每个任务的公平性。



### 优先级

普通任务之间还是有优先级区分的，所以在考虑vruntime的同时还要考虑普通任务的权重值，内核中会有一个 nice 级别与权重值的转换表，**nice级别越低，权重值就越大**。于是有了下面这个公式：
$$
vruntime = vruntime + delta\_exec * \frac{NICE\_0\_LOAD}{权重}
$$

- delta_exec：实际运行时间
- NICE_0_LOAD：一个常量，表示nice 0进程加载的权重。



### 调整优先级

​	如果想让某个普通任务有更多的执行时间，可以调整任务的 `nice`值，`nice`值的设置范围是 -20 ~ 19，值越低，表明优先级越高。注意：实际上nice值并不表示优先级，而是表示优先级的修正数值，它与优先级的关系：
$$
priority_{new} = priority_{old} + nice
$$
priority的范围是 0 ~ 139，其中前面的0 ~ 99 范围是提供给实时任务使用的。



## 中断和异常

### 中断

在计算机系统中，中断（Interrupt）是一种**由硬件或软件发出的信号**，用于引起处理器对某个事件的注意。当中断发生时，处理器会暂停当前正在执行的任务，转而去处理中断请求，处理完成后再返回原来的任务。中断机制是实现并发处理、提高系统效率的重要手段。

中断主要分为两种类型：**硬件中断**和**软件中断**。

1. 硬件中断：**硬件中断是由外部设备或内部硬件条件**（例如定时器、I/O设备、内存错误等）引发的中断。这种中断通常是**异步的**，即它们可以在任何时间点发生，不依赖于正在运行的程序。

2. 软件中断：**软件中断是由运行中的程序主动发出的**，用于请求操作系统提供某种服务，比如系统调用。软件中断是**同步的**，即它们的发生是在程序的控制下，与程序的运行步骤有关。



### Linux中的中断处理

 Linux 系统为了解决中断处理程序执⾏过⻓和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」 

- 上半部分用来快速处理中断：一般会**暂时关闭中断**请求，主要负责处理跟硬件紧密相关或者时间明感的事情。
- 下半部分用来延迟处理上半部分未完成的工作：一般以**内核线程**的方式运行



### 中断和异常的区别

中断和异常都是系统对某些特殊事件的响应，它们都会导致CPU暂停当前的任务，转而处理这些特殊事件。

1. **来源**：中断通常来自系统外部，比如用户输入、硬件设备的信号等。例如，当你按下键盘上的一个键，键盘会发送一个中断信号给CPU，CPU停止当前的工作，转而处理这个按键事件。异常则通常来自系统内部，比如程序执行过程中的错误、违规操作等。例如，当一个程序试图除以零，就会触发一个除零异常。

2. **同步性**：中断是异步的，它可以在任何时间点发生，与CPU当前正在执行的指令无关。而异常是同步的，它总是在某个具体的指令执行过程中发生。

3. **处理方式**：对于中断，操作系统通常会保存当前任务的状态，然后跳转到一个中断处理程序来处理中断事件，处理完后再恢复原来的任务。对于异常，操作系统通常会试图修复引起异常的错误，如果不能修复，就会终止引起异常的程序。

4. **响应时间**：中断的响应时间通常比较长，因为需要保存和恢复任务状态，而且中断处理程序可能需要进行一些复杂的操作。异常的响应时间通常比较短，因为只需要检查和修复错误。

在Linux中，中断和异常的处理机制是通过中断描述符表（Interrupt Descriptor Table, IDT）实现的。每种中断和异常都有一个对应的中断向量，这个向量是一个指向中断或异常处理程序的指针。当中断或异常发生时，CPU会根据中断向量找到对应的处理程序，然后跳转到这个程序去处理中断或异常事件。

### 时钟中断

**时钟中断**是由硬件定时器（如 x86 上的 HPET/APIC 或 ARM 上的 Generic Timer）每隔一定时间周期性发出的中断信号，**通知 CPU 执行一个与时间有关的处理逻辑**。

> 操作系统！时间到了，请处理一下时间相关的事情，比如换人（调度）啦！

**一个时钟中断 ≠ 一次进程切换**，但是：

- 每次中断都检查当前进程的时间片是否用完；
- 如果时间片耗尽 → `need_resched` 标志置 1；
- 中断返回时触发 `schedule()` 执行切换。

## 为什么0.1 + 0.2 != 0.3

### 计算机中的数值表示

#### 有符号数

1. **原码表示法**：符号位为0表示正数，符号位1表示负数，数值位即真值的绝对值。

2. **补码表示**：

   - 正数：补码与原码相同
   - 负数：符号位不变，其余位按位变反再加1

   表示范围（n为总位数包含1位符号位）：
   $$
   -2^{n-1} <= x <= 2^{n-1}-1
   $$
   因为补码用-0对应的二进制代码：1000000表示负数的最小值，故负数表示范围大于正数。

3. **反码表示**：

   - 正数：反码与原码相同
   - 负数：除符号位外其余位全部变反。

   表示范围：
   $$
   -2^{n-1}-1 <= x <= 2^{n-1}-1
   $$

4. **移码表示**：

   移码与原码：

   	负数：原码与符号位一同变反，末位加1
   	
   	正数：原码的符号位变反

   补码与原码：

   	符号位相反，数值位相同	

#### 数的定点表示和浮点表示

两种方法表示小数点的存在：定点表示的数称称**定点数**，浮点表示的数称**浮点数**。

1. 定点表示：

   小数点固定在某一位置的数为定点数，有以下两种格式：

   小数表示法：

   ![](img/6-1.JPG)

   整数表示：

   ![](img/6-2.JPG)

   定点机中小数的表示范围（n不含符号位）：
   $$
   -（1-2^{-n} - 1) <= X <= (1 - 2 ^{-n})
   $$
   定点机中整数表示范围（n不含符号位）
   $$
   -（2^{n} - 1） <= X <= (2^{n} - 1)
   $$

2. 浮点表示

   浮点数表示形式：

   ![](img/6-3.JPG)

   阶码是整数，阶符和阶码的位数m合起来反映浮点数表示的范围及小数点实际的位置。

   尾数是小数，其位数n反应了浮点数的精度。尾数的符号位代表浮点数的正负。

   *浮点数表示的范围*：
   $$
   最小负数：2^{2^m-1} * -1
   $$

   $$
   最大负数：2^{-2^m} * (-2^{-1} - 2^{-n})
   $$

   $$
   最小正数：2^{-2^m} * 2^{-1}
   $$

   $$
   最大正数: 2^{2^m -1} * (1 - 2^{-n})
   $$

   常用浮点数：

   | 总位数 | 阶码（含一位阶符） | 尾数（含一位数符） |
   | ------ | ------------------ | ------------------ |
   | 32     | 8                  | 24                 |
   | 64     | 11                 | 53                 |
   | 80     | 15                 | 65                 |

   **浮点数的规格化**：

   当基数为2时，尾数最高位为1的数称为规格化数。规格化时尾数左移一位，阶码减一（左规），尾数右移一位，阶码加一（右规）

   **定点数与浮点数的比较**：

   1. 当浮点数和定点数的位数相同时，浮点数的表示范围>定点数的表示范围
   2. 当浮点数为规格化数时，其相对精度高于定点数
   3. 浮点数的运算速度低于定点数、硬件成本高

   **IEEE754标准**

   ![](E:/Documents/interview-trivia-question/img/6-4.JPG)

   只有一位数符表示浮点是的正负，阶码用移码表示。

   **无穷的表示**：

   	阶码各位全为1，且尾数各位全为0时。

   **无效浮点数**：

   	阶码各位全为1，且尾数各位不全为0，为无效浮点数。

   **注意：IEEE754中默认尾数是规格化数，且将最高位的1省略**。

#### 定点运算

**算术移位**

	正数左移右移均补0
	
	负数：

1. 原码：左移右移均补0
2. 补码：左移补0，右移补1
3. 反码：左移右移均补1

**加减法运算**

	若机器采用补码，求`A-B`时，需要先求`-B`的补码，然后将结果和`A`相加。`-B`的补码求法：将`B`的补码，连同符号位一同变反再加1。

**乘法运算**

1. 原码一位乘法（n次）

   X=0.1101，Y = -0.1011， 求XY=?

   设寄存器A = 00.0000， B = |X| 00.1101， C=|Y| = .1011

   1. 取C最低位，若为1执行`A + B`否则执行`A + 0`然后将B右移1位进入C的符号位，C的最低位丢弃。
   2. 重复1，直到C小数部分丢弃完。

   ![](E:/Documents/interview-trivia-question/img/2-1.JPG)

2. 补码一位乘法（n+1步）

   

**溢出判断**

	溢出判断有两种方法：用**一位符号位判断溢出**和用**两位符号位判断溢出**

1. 一位符号位判断：两个操作数符号位相同（减法时即为被减数和”求补“以后的减数），结构又与原操作数符号不同则溢出。

2. 两位符号位判断：当2位符号位不同时，表示溢出。无论是否发生溢出，最高位符号永远代表真正的符号。

   例如：

   假设符号位`01`那么代表溢出，又有高位为`0`表示正溢出。

#### 浮点四则运算

**浮点数加减运算**：

	当浮点数阶码不同的时候，小数点的位置也不同，故进行浮点数加减运算需要以下几个步骤

1. 对阶，使两数的小数点位置对齐。
2. 尾数求和，将对阶后的两尾数按定点加减运算规则求和
3. 规格化，通过左移，右移将尾数规格化
4. 舍入：考虑右移时丢失的精度值
5. 溢出判断：判断结果是否溢出

**对阶**：

	首先要求出阶差，再按小阶向大阶看齐的原则，使阶小的尾数右移（小数点左移），每右移一位，阶码加1，直到两个阶码相等。尾数右移可能会发生数码丢失，影响精度。

**规格化**：

	采用**双符号位的规格化**：
	
	当`S>0`，时补码规格化形式为

$$
[S]_补 = 00.1xxxx...x
$$

	当`S<0`，时补码规格化形式为

$$
[S]_补 = 11.0xxxx...x
$$

	当尾数的最高数值位与符号位不同时，即位规格化形式，但对`S < 0`时，有两种特殊处理

1. 规定`-1/2`不是规格化的数（对补码而言）
2. `S = -1`即`11.00...0`视为规格化的数

**舍入**：

	常用的舍入方法有`0舍1入`法和`恒置1法`

1. 0舍1入

   右规时，被移去的最高位为0，则舍去；最高位为1，则在尾数的末位加1。

2. 恒置1法

   右规时，无论最高位是0/1，尾数末尾都恒置1

### 十进制小数与二进制的转换

对于小数部分，我们采用乘2取整法。将十进制中的小数部分乘2作为二进制的一位，然后继续取小数部分乘2，作为下一位，直到不存在小数为止：

<img src="img/float-10-2.png" style="zoom:50%;" />

但是并不是所有的小数，都可以用二进制表示，由于计算资源有限，所以我们只能最大化接近某些小数，从而导致了某些精度损失。

# 内存屏障(memory barriers)

单核cpu时代，我们写的一行行代码执行的顺序就是我们执行的顺序，但是在多核cpu时代由于各种原因，需要同步手段，否则不同线程看到的执行顺序有可能是完全不同的。

## 为什么会引入乱序执行

现代 CPU 引入 **乱序执行（Out-of-Order Execution, OoOE）**，本质上是为了 **榨干流水线效率，提高吞吐量**。

**单纯的顺序执行有什么问题？**

- 指令在流水线中排队时，会遇到“阻塞”：
  - **数据相关性**：一条指令要用到前一条的结果，就得等。
  - **内存访问延迟**：从 L3 cache / 内存取数据可能几十到几百个时钟周期。
  - **分支预测失败**：需要等结果回来才能决定下一条指令走哪边。

如果严格按照程序顺序执行，这些 stall（停顿）会导致 **CPU 大量时钟周期空转**，浪费性能

> 时钟周期:

所以乱序执行的核心思想是:

**指令之间不一定都有依赖。**

- 如果指令 B 不依赖指令 A 的结果，那么即便 A 还没完成，B 也可以先执行。
- CPU 通过 **指令调度器（scheduler）** 和 **寄存器重命名** 技术，把不相关的指令重排，最大化利用执行单元。

```
; 原始顺序
LOAD R1, [addr1]   ; 访问内存，可能要 200 cycles
ADD  R2, R3, R4    ; 简单加法，1 cycle
MUL  R5, R6, R7    ; 乘法，3 cycles

; 乱序执行可能变成
ADD  R2, R3, R4    ; 提前执行
MUL  R5, R6, R7
LOAD R1, [addr1]   ; 等内存慢慢回来

```

虽然这些指令CPU内部乱序，但 **程序员看到的效果应该像顺序执行**（即 *程序语义不能变*）。所以 CPU 要维护一个 **重排序缓冲区（Reorder Buffer, ROB）**：

+ 指令可能乱序执行，但提交（commit）结果时必须按照原始顺序写回寄存器/内存。

+ 这样保证单线程执行时，结果和顺序执行一致。

多核共享内存时就麻烦了：

- 一个 CPU 内核看到“按程序顺序”，另一个内核可能看到的是“被重排后的顺序”。
- 这就是为什么要引入 **内存模型** 和 **内存屏障**，告诉硬件/编译器“这里不能乱动，必须保证顺序”。

在程序实际运行的时候可能并不会按照编写好的指令顺序访问内存：

+ 编译时，编译器可能会优化进程指令重排导致内存乱序访问。
+ 运行时，多CPU间交互引入内存乱序访问。

对于单线程程序一般内存乱序不会有什么问题，但是对于多线程程序，逻辑的正确性会依赖内存访问的顺序

*引入 **内存屏障**可以让屏障之前的内存访问 一定先于之后的完成。*

**编译时内存乱序**

可以使用类似barrier()或者volatile关键字

**运行时内存乱序**

运行时，CPU本身是会乱序执行指令的。



# 虚拟相关

## malloc实现

### malloc数据结构

以ptmalloc为例：

1. **双向链表：管理空闲块**

- 每个“内存块（chunk）”由一个结构体表示，其中包含：
  - 内存块大小
  - 使用状态（free / used）
  - 指向前后空闲块的指针
- 所有空闲块形成 **双向链表** 或多个**大小分组的链表桶（bins）**。

🔹 2. **快速分配表 fastbin / tcache**

- 对于小内存块（如 < 64 bytes），glibc 使用 **fastbin（快速回收链表）** 或 **tcache（线程缓存池）** 来提高小块内存分配效率。

🔹 3. **分段管理**

- 将内存分成不同的“bin”：fastbin, small bin, large bin，按块大小组织，便于快速定位合适的空闲块。

🔹 4. **堆扩展**

- 若内存不足，`malloc` 会调用：
  - `brk/sbrk`：向堆尾申请更多空间；
  - `mmap`：直接映射一块匿名内存（通常用于大块分配）。

### 内存碎片如何处理

内部碎片分了外部和内部两种。

+ 外部碎片： 指的是虽然总内存空间是够的，但是分散成了很多小块，导致无法找到一个连续的大内存
+ 内部碎片： 分配的内存块大于实际需要，造成浪费。

### 常见碎片整理方法

1. **首次适配（First Fit）**

- 从头开始找第一块足够大的空闲块来分配。
- 简单但可能在低地址留下很多小碎片。

2. **最佳适配（Best Fit）**

- 找最小但足够大的空闲块，节省空间。
- 易造成大量小碎片，性能也略差。

3. **最差适配（Worst Fit）**

- 找最大空闲块分配，让剩余空间还比较大。
- 较少使用，表现不如上面两种。

4. **伙伴系统（Buddy System）**

- 常用于内核或 slab 分配器中。
- 将内存按2的幂次划分，释放后可与相邻“兄弟块”合并，减少碎片。

## 加载二进程程序的过程

执行二进制程序（例如在 Linux 下运行 "./helloworld"）时，其实发生了很多幕后工作，可以从用户空间到内核空间分几个主要步骤说明：

1. 命令解析与系统调用
     - 当你在 shell 中输入 "./helloworld"，shell 先解析该命令，查找对应的可执行文件（即当前目录下的 helloworld）。
        - shell 调用 fork() 创建一个子进程，然后在子进程中调用 execve() 系列系统调用（实际上 execve() 是最常用的）来加载并执行该二进制文件。
2. 内核加载过程（execve 调用进入内核）
     - 内核接管控制后，会首先检查文件的执行权限，并验证该文件是否是有效的可执行格式。Linux 中常见的可执行格式是 ELF（Executable and Linkable Format）。
        - 内核读取 ELF 文件头和各个节的信息（如程序头表），判断需要加载哪些段（例如代码段、数据段和 BSS 段）以及它们各自的内存映射属性（只读、可写、可执行）。
3. 建立进程地址空间
     - 内核为该进程构建地址空间，包括映射程序的各个段到合适的虚拟内存地址。通常，代码段（text）是只读可执行的，数据段（data）是可写的，BSS 段会被清零。
        - 同时，内核会设置栈空间（stack）和堆空间（heap），并在栈上放入命令行参数（argv）、环境变量（envp）以及辅助向量（auxv），供用户程序初始化时使用。
4. 动态链接和共享库加载（如果是动态链接程序）
     - 对于动态链接的 ELF 程序，内核会加载动态链接器（例如 /lib/ld-linux.so.*）到内存。
        - 动态链接器负责解析程序依赖的共享库（如 libc 等），进行符号重定位，确保各个函数和全局变量正确链接。这一过程可以看作是“运行时链接”。
5. 转向用户程序入口点
     - 内核在完成内存映射、参数设置和动态链接后，将控制权转给程序的入口点（通常是在 ELF 文件中指定的 _start）。
        - _start 通常完成一些初始化工作（例如初始化全局对象、调用构造函数等），然后最终调用 main() 函数。
6. 程序运行
     - 一旦 main() 函数被调用，程序便开始执行你编写的业务逻辑。
        - 程序结束时，通常通过 return 或调用 exit() 收尾，并将退出状态传递给内核，内核再通知调用者（如 shell），表示该进程已经结束。
7. 系统资源回收
     - 当进程终止后，内核会清理进程所占用的资源（如内存、文件描述符等）。

## 虚拟内存

虚拟内存是操作系统提供的一种机制，它使得进程能够使用比实际物理内存更多的内存，并且使得每个进程都认为自己拥有独立的内存空间。

通过这个虚拟内存机制，每个进程有自己的 **虚拟地址空间**，操作系统通过虚拟内存将多个进程的内存空间隔离开来，保证一个进程不会访问另一个进程的内存区域，避免了直接操作物理内存可能会造成很多错误。虚拟内存使得操作系统能够**懒加载**内存。进程不需要一次性分配和加载所有内存，只有在需要时才会加载实际数据，这样可以减少内存浪费。

工作机制：操作系统给每个进程分配页表，页表中的内容是虚拟地址与物理地址的映射关系，当进程访问某个地址的时候，通过CPU提供的MMU机制找到真实物理地址。如果该虚拟页面没有加载到物理内存（页面错误），操作系统会从磁盘加载数据到内存。





### 虚拟地址和物理地址

操作系统管理虚拟地址和物理地址的方式主要是：**内存分段**和**内存分页**。

#### 分段机制

分段机制下的虚拟地址由两部分组成，**段号**和**段内偏移量**。

<img src="./img/segement-trans.png" style="zoom:50%;" />

分段机制的不足：

- 会出现**内存碎片问题**

  - 外部内存碎片：多个不连续的小内存导致程序无法被装载
  - 内部内存碎片：程序有部分的内存可能并不是很常使⽤，这也会导致内存的浪费；

- 内存交换效率低

  **内存交换，用于解决外部碎片问题**，其期望通过将当前不连续的内存空间通过交换技术整理为连续的内存空间。但是由于硬盘访问速度与内存的差异，导致如果一次交换大量内存整个系统都会卡顿。



#### 分页机制

​	分段机制的好处是能够获得连续的内存空间，但是会出现内存碎片和交换效率低下的问题（交换内存过大）。为了解决这些问题，提出了分页机制。

分页机制：将整个虚拟和物理内存空间切成一段固定大小的连续连续空间。在linux上一页大小通常会4KB。虚拟地址和物理地址通过页表来进行操作：

<img src="img/page-trans.png" style="zoom:50%;" />

**页表是存储在内存里的**，内存管理单元`MMU`负责将虚拟内存地址转换为物理内存地址。



分页机制的不足：

- 内存浪费

  在一级页表中，**每个进程都需要一个完整的页表**，**即使进程只使用了一小部分虚拟地址空间**。例如，对于一个 32 位系统，虚拟地址空间的大小为 4GB，如果每个页面的大小为 4KB，那么就需要 1M 个页表条目来覆盖整个虚拟地址空间。如果每个页表条目占用 4 字节，那么**每个进程的页表就需要 4MB 的内存**。
  $$
  4GB(2^{32}) / 4KB(2^{12}) = 1MB(2^{20})
  $$

#### 多级页表

假设还是上面的场景，现在我们将1MB的页表项，再分页，每1024个页表项分一页，分1024页。得到如下地址映射

<img src="./img/page-trans-2.png" style="zoom:50%;" />

使用多级页表减少内存空间的原理：**根据局部性原理，大部分程序用不到4GB的内存空间**，因此如果某个⼀级⻚表的⻚表项没有被⽤到，也就不需要创建这个⻚表项对应的⼆级⻚表了，即可以在需要时才创建⼆级⻚表。做个简单的计算，假设只有 20% 的⼀级⻚表项被⽤到了，那么⻚表占⽤的内存空间就只有 4KB（⼀级⻚表） + 20% * 4MB（⼆级⻚表） = 0.804MB ，这对⽐单级⻚表的 4MB 是不是⼀个巨⼤的节约。



## 交换空间和虚拟内存的关系

**交换空间（Swap Space）和虚拟内存（Virtual Memory）都是计算机系统中用于扩展物理内存（RAM）的技术**。他们的**主要目标是让系统可以运行更多的程序，即使这些程序的总内存需求超过了物理内存的大小**。

虚拟内存是一种内存管理技术，它让应用程序认为它们有更多的RAM（物理内存）可用，而实际上，系统可能正在使用硬盘空间来模拟额外的RAM。这是通过将内存中的信息（称为页面）移动到硬盘上的特定区域（称为页面文件或交换空间）来实现的。当这些页面需要被访问时，它们会被移回RAM，可能会替换掉一些不常用的页面。

**交换空间是虚拟内存系统的一部分，是硬盘上预留出来的一部分空间，用于存放从RAM中移出的页面**。当系统的物理内存不足时，操作系统可以将一些暂时不用或者使用频率较低的内存页面（page）移动到交换空间，从而释放出物理内存空间给新的程序使用。当这些被移动到交换空间的内存页面再次被需要时，操作系统会将其从交换空间移回物理内存。

**交换空间是虚拟内存实现的一种具体机制，是虚拟内存系统中的一个组成部分**。



## 磁盘的Swap区与文件区的区别

文件区：主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理**采用离散分配方式**  

Swap区：由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出速度，因此**通常对换区采用连续分配方式**  。



## 快表

快表，又称**联想寄存器**(TLB) ，是一种**访问速度比内存快很多的高速缓冲存储器**，用来**存放当前访问的若干页表项**，以加速地址变换的过程 。

![](./img/fast-table.JPG)



## 缺页中断

完整流程

```c++
1.CPU 检查页表，发现页不存在
  程序访问了一个虚拟地址，比如 mov eax, [0x12345000]
	CPU 查找页表，发现：
		该虚拟页尚未映射；
		页表项中的 P 位（Present bit）为 0；
	触发缺页异常（Page Fault Exception），中断当前执行。
2.CPU 切换到内核态，执行 Page Fault 处理例程
	保存当前上下文（EIP/RIP、寄存器等）；
	切换到内核态堆栈；
	跳转到中断向量表中的 page fault handler，例如 Linux 中是 do_page_fault()。
3.操作系统内核检查访问是否合法
  是否是有效地址？
	该地址是否属于某个有效的 VMA（Virtual Memory Area）？
	否则触发段错误（SIGSEGV）；访问权限是否正确？
	如果页面是只读的，而你尝试写入 → 触发写保护错误（可触发 COW 或信号）
4.内核分配物理页并建立映射
  如果一切合法，则：
  从页缓存（page cache）或磁盘文件中加载页面内容；
  为该虚拟页分配一个空闲物理页；
  更新页表（PTE）：
    设置有效（Present = 1）
    设置权限位（读/写/执行等）；
  TLB 失效，等待下一次访问重载（或直接 reload）；
5.恢复用户态程序继续执行
  恢复寄存器、栈等上下文；
  跳回被中断的指令，重新执行；
  由于现在该虚拟页已经有效，这次不会再触发缺页。
```







当CPU访问的页面不在物理内存中就会产生缺页中断，缺页中断与一般的中断主要的区别：

- 缺⻚中断在**指令执⾏「期间」产⽣**和处理中断信号，⽽⼀般中断在⼀条**指令执⾏「完成」后**检查和处理中断信号  。
- 缺⻚中断返回到该指令的开始重新执⾏「该指令」，⽽⼀般中断返回回到该指令的「下⼀个指令」执⾏。

<img src="./img/no-page-interrupt.png" style="zoom: 67%;" />



## 页面置换算法

⻚⾯置换算法的功能是， 当**出现缺⻚异常**，需调⼊新⻚⾯⽽**内存已满**时，**选择被置换的物理⻚⾯**，常见的页面置换算法有：

1. **最佳页面置换算法（Optimal Page Replacement Algorithm）**：这是一种理论上的最佳策略，它总是选择将来最久不会被访问的页面进行置换。然而，在实际操作中，我们无法预知未来的页面访问顺序，因此这种算法无法实现。
2. **先进先出（FIFO）页面置换算法**：这种算法总是选择最早加载到内存中的页面进行置换。尽管实现简单，但可能导致频繁的页面错误（即需要的页面不在内存中），特别是当较新的页面被频繁访问时。
3. **最近最少使用（LRU）页面置换算法**：这种算法选择最长时间未被访问的页面进行置换，以此来预测未来也不太可能被访问的页面。实现LRU算法需要跟踪所有页面的访问历史，这可能会引入一定的开销。
4. **时钟（Clock）页面置换算法**：这是一种近似LRU的算法，但是它只需要一个循环队列和一个指针。每个页面有一个访问位，当页面被访问时，位设置为1。当需要进行页面置换时，指针开始循环，将访问位为0的页面置换出去，如果访问位为1，则将其设置为0并继续移动。这种算法也被称为最近未使用（NRU）算法。
5. **最不常用（LFU）页面置换算法**：这种算法记录每个页面被访问的次数，并选择最少被访问的页面进行置换。这种策略可能会导致一些问题，例如，一个页面如果一开始被频繁访问，但后来很少被访问，这个页面可能会长期停留在内存中。

## 操作系统内存不足的时候会发生什么

使用malloc申请内存的时候，实际上申请的虚拟内存，只有当申请的内存被访问的时候，CPU才会去查看页表是否映射了这块内存，如果没有CPU产生缺页中断。此时从用户态进入内核态，内核态的缺页中断函数会查看是否有空闲的物理内存，如果有直接分配，如果没有就需要进入内存回收

+ 后台内存回收：物理内存紧张的时候，会唤醒kswapd内核线程来回收内存，这是 **异步的回收**
+ 直接内存回收：如果后台异步回收的速度跟不上进程内存申请的速度，就开启直接回收， 这个回收过程是 **同步的**

如果开启同步回收还是无法满足物理内存的申请，就触发 **OOM**机制

OOM机制会根据算法选择一个占用物理内存高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM killer会继续选择物理内存占用高的进程，直到释放足够的内存位置。

---

回收的时候具体回收哪些呢？

![image-20250413142008715](assets/image-20250413142008715.png)

# 进程相关

## 线程与进程的比较

- 进程是资源（包括内存、打开的⽂件等）分配的单位，线程是 CPU 调度的单位；
- 进程拥有⼀个完整的资源平台，⽽线程只独享必不可少的资源，如寄存器和栈；
- 线程同样具有就绪、阻塞、执⾏三种基本状态，同样具有状态之间的转换关系；
- 线程能减少并发执⾏的时间和空间开销
  -  **线程的创建时间⽐进程快**，因为进程在创建的过程中，还需要资源管理信息，⽐如内存管理信息、⽂件管理信息，⽽线程在创建的过程中，不会涉及这些资源管理信息，⽽是共享它们  
  -  **线程的终⽌时间⽐进程快**，因为线程释放的资源相⽐进程少很多  
  -  **同⼀个进程内的线程切换⽐进程切换快**，因为线程具有相同的地址空间（虚拟内存共享），这意味着同⼀个进程的线程都具有同⼀个⻚表，那么在切换的时候不需要切换⻚表。⽽对于进程之间的切换，切换的时候要把⻚表给切换掉，⽽⻚表的切换过程开销是⽐较⼤的  
  -  线程之间数据传递的时候，就不需要经过内核了，这就使得**线程之间的数据交互效率更⾼**

<img src="assets/image-20250414171449857.png" alt="image-20250414171449857" style="zoom:50%;" />

<img src="assets/image-20250414171524525.png" alt="image-20250414171524525" style="zoom:50%;" />

### 切换的上下文是什么

进程的上下文切换不仅包含了虚拟内存，栈、全局变量等用户空间的资源，还包含了内核堆栈，寄存器等内核空间的资源。

通常会把要交换的信息保存在进程的PCB中，运行另一个进程的时候就需要从这个新进程的PCB中取出上下文，然后回复到CPU中。回复到CPU中的内容包括了寄存器、程序计数器.

### 协程

**协程 (Coroutine)**:

- **协程**是一种更轻量级的线程，它基于用户态实现而非操作系统内核态。
- 协程允许在单线程中实现并发，通过用户代码协作切换。
- 协程不需要操作系统的上下文切换，切换开销低，但无法利用多核（除非多个协程被分配到不同的线程上）。

## 内核态与用户态





内核态和用户态是操作系统中的两种运行模式。它们的主要区别在于权限和可执行的操作：

+ 内核态： 内核态下，CPU可以执行所有的指令和访问所有的硬件资源，这种模式下的操作具有更高的权限，主要是用于操作系统内核的运行
+ 用户态： 用户态下，CPU只能执行部分指令集，无法访问内存硬件资源，这种模式下的操作权限低，主要是用于运行用户程序。

内核态的底层操作主要包括:内存管理、进程管理、设备驱动程序控制、系统调用等.这些操作涉及到操作系统的核心功能，需要较高的权限来执行.
分为内核态和用户态的原因主要有以下几点：

+ 安全性:通过对权限的划分，用户程序无法直接访问硬件资源，从而避免了恶意程序对系统资源的破
  坏.

+ 稳定性:用户态程序出现问题时，不会影响到整个系统，避免了程序故障导致系统崩溃的风险。

+ 隔离性:内核态和用户态的划分使得操作系统内核与用户程序之间有了明确的边界，有利于系统的模块化和维护.

  

  内核态和用户态的划分有助于保证操作系统的安全性、稳定性和易维护性

### 内核态和用户态之间如何通信

> 你可以分为「主动返回」和「异步通知」两类来说：
>
> #### **(1) 系统调用返回值 / errno**（同步、最常见）
>
> - 用户态发起系统调用，陷入内核态。
> - 内核执行完逻辑后，把结果通过 **返回值** 或 **errno** 传递回用户态。
>    👉 这是最常见的「内核 → 用户」消息方式。
>
> #### **(2) 信号 (signal)**（异步）
>
> - 内核可以给用户进程发送一个信号（如 `SIGINT`, `SIGKILL`）。
> - 用户进程可以捕捉信号并执行对应的 handler。
>    👉 类似于内核对用户进程的“异步消息通知”。
>
> #### **(3) 文件/设备接口（read/write/ioctl）**
>
> - 驱动程序会把硬件事件写入到某个设备文件（如 `/dev/...`）。
> - 用户态进程通过 `read()`/`ioctl()` 来读取数据。
>    👉 这种方式是 **用户轮询或阻塞等待内核消息**。
>
> #### **(4) 共享内存 + 映射 (mmap)**
>
> - 内核分配一段内存，映射到用户空间。
> - 内核写数据到这块共享区，用户态可以直接读。
>    👉 常用于高效传输数据，但需要配合事件通知机制（比如信号或 `futex`）告诉用户进程有新数据。
>
> #### **(5) Netlink Socket**
>
> - Linux 专门设计的一种 **用户态 ↔ 内核态** 双向通信机制。
> - 网络子系统、路由表、Netfilter 防火墙规则等，常通过 netlink 传递。
>
> #### **(6) `futex` / eventfd / epoll**（更现代的事件通知机制）
>
> - 内核通过改变某些内核对象的状态，用户态通过 `epoll_wait()` 等系统调用感知变化。
> - 这种属于 **事件驱动的通知方式**。
>
> 总结回答：
>
> 内核态给用户态发消息有几种常见方式。最简单的是通过系统调用返回值来传递结果，这是同步的。
>  如果需要异步通知，内核会通过 **信号** 通知用户进程，比如硬件中断后给用户态发 `SIGIO`。
>  另外，还有更复杂的通信方式，比如 **共享内存映射**、**netlink socket**，这些常用于内核子系统和用户进程的交互。
>  总的来说，机制可以分为「返回值/errno」、「信号」、「文件接口/阻塞读」、「共享内存+事件」、「专用 socket」几类。

### 如何进入内核态

 **系统调用（System Call）** 👉 最常见方式

- 用户程序通过**系统调用**请求操作系统服务（如读文件、网络通信、进程管理等）。
- 底层实现方式是：
  - x86 架构常用 `int 0x80`（早期）或 `syscall` 指令（64位系统）。
  - ARM 架构使用 `svc` 指令。

🧠 举例：

- `read()`, `write()`, `open()`, `fork()`, `mmap()` 等都是通过系统调用进入内核态。

**异常或中断（Exception / Interrupt）**

- **中断**：如键盘输入、网卡接收数据等硬件中断发生时，CPU 会自动切换到内核态，调用中断处理程序。
- **异常**：如**除以0**、**段错误（segfault）**、**缺页异常（page fault）**，CPU 检测到异常后，也会进入内核态处理。

🧠 举例：

- 按下键盘 → 触发中断 → CPU 切换到内核态 → 调用中断服务例程（ISR）。
- 程序访问非法地址 → page fault → 内核处理缺页。

**软中断 / 信号机制**

- 有些系统使用**软中断机制**作为通信手段，也会触发从用户态进入内核态。
- **Linux 信号机制**（如 `SIGSEGV`, `SIGINT`）也会触发进内核态处理。

态切换的时候会发送

| 操作         | 说明                                   |
| ------------ | -------------------------------------- |
| CPU 模式切换 | 从用户态切换为内核态（Ring3 → Ring0）  |
| 栈切换       | 使用内核栈（每个线程都有自己的内核栈） |
| 保存现场     | 保存用户态的寄存器状态                 |
| 跳转执行     | 跳转到内核中的服务程序或中断处理例程   |

### 系统调用和普通函数调用的区别？系统调用的简单原理?

| 特点     | 普通函数调用                            | 系统调用                                           |
| -------- | --------------------------------------- | -------------------------------------------------- |
| 运行空间 | 仅在 **用户态** 执行                    | 需要从 **用户态切换到内核态**                      |
| 权限     | 只能访问用户态内存，权限受限            | 拥有内核态特权，可以操作硬件、内存管理、进程调度等 |
| 开销     | 开销小，就是 **压栈、跳转、执行、返回** | 开销大，需要 **陷入内核、上下文切换、检查权限**    |
| 示例     | `printf()`, `strcpy()`                  | `read()`, `write()`, `open()`, `socket()`          |

👉 本质区别：

- 普通函数调用只是 **用户态代码在同一权限级别下的跳转**。
- 系统调用是 **用户态请求内核态服务，需要陷入内核态才能执行**。

> ## 2️⃣ 系统调用的简单原理
>
> 可以分为 **三个阶段**：
>
> 1. **用户态发起请求**
>    - 用户程序调用 C 库函数（如 `read()`），其实这个函数最后会触发一个特殊的指令（如 `syscall` 或 `int 0x80`），告诉 CPU 切换到内核态。
> 2. **陷入内核态**
>    - CPU 执行指令后，切换到更高权限（ring 0），跳转到内核中预定义的 **系统调用入口表**，根据系统调用号找到对应的内核函数，比如 `sys_read()`。
> 3. **执行并返回结果**
>    - 内核完成操作（例如从磁盘读数据），把结果放入寄存器/内存。
>    - CPU 执行 `sysret`（或类似指令），切回用户态，把返回值交给用户程序。

## 调用fork、vfork、clone

### fork

fork() 在 UNIX/Linux 中用于创建一个新进程（子进程），它会复制父进程的大部分内容。不过，为了效率，现代操作系统（如 Linux）通常使用“写时复制”（Copy-On-Write, CoW）的策略，即在 fork() 后父子进程最初共享同一物理内存，只有当其中一方试图修改内存数据时，才为该进程单独分配一份副本。下面详细说明 fork() 会复制哪些内容以及一些注意事项：

1. 虚拟地址空间
     - 父进程的整个虚拟地址空间都会被复制给子进程，这包括代码段、数据段、堆、栈等。
        - 采用写时复制机制，直到父进程或子进程做写入操作时才真的分配新的物理内存。
2. 程序计数器和寄存器状态
     - 子进程会得到父进程的寄存器、程序计数器（PC）、堆栈指针等的复制，这保证了 fork() 返回后，父子进程都从 fork() 调用处继续执行，不过返回值不同：子进程返回 0，父进程返回子进程的 PID。
3. 文件描述符
     - 父进程打开的文件描述符会被复制到子进程中，并且它们共享同一个打开文件表项（即共享文件偏移量和文件状态标志）。
        - 这意味着父子进程都能继续使用已经打开的文件，但如果其中一个进程修改文件偏移量，对另一个进程也会有影响。
4. 信号处理器和阻塞的信号集合
     - 子进程会继承父进程的信号处理设置（即 signal handler），以及当前被阻塞的信号集合。
5. 环境变量和进程上下文
     - 父进程的环境变量、进程优先级、资源限制等会被复制到子进程。
6. 进程映射文件
     - 如果父进程中有内存映射的文件（mmap），这些映射会在子进程中复制，但两进程对该内存区域的修改，是否共享以及同步要看 mmap 的标志（比如 MAP_SHARED）。
7. 后台信息
     - 子进程会继承父进程的工作目录、用户ID、组ID、根目录等。

需要注意的几点：

• 父子进程是两个独立的进程，尽管刚 fork 后内容相同，但它们各自的写操作不会影响对方（因为写时复制机制会让内存页复制给修改的一方）；

• 不复制一些内核级资源，例如系统 V IPC 资源、信号量、某些锁等，这些资源需要特殊处理，或者父子进程可能需要手动同步或重新建立连接；

**写时复制" (Copy-on-Write, CoW)：**

- 写时复制将复制操作推迟到第一次写入时，也就是fork的时候不会立刻把父进程的虚拟内存空间中的内容全部复制，因为很耗时。特别是假如进场复制后马上执行了`exec` 那么这个复制操作不就是完全duo
- 父子进程初期共享相同的内存区域，但当其中一个进程尝试写入内存时，会触发**内存页复制**，然后分别拥有独立的内存块。

### vfork

vfork比fork更激进：

- `vfork()` 不会复制父进程的内存空间。
- 子进程和父进程在同一地址空间中运行（共享地址空间）。

在 `vfork()` 调用返回后，父进程会被**挂起阻塞**，直到子进程使用 `exec()` 加载新程序或调用 `exit()` 终止子进程。这样可以避免父子进程间的冲突（因为二者共享内存空间）。所以vfork更适合的场景是,vfork创建一个新进程的目的就是为了exec执行另一个程序（可以这样想vfork与父进程共享地址空间，就有点像线程的概念）。

优点是，连内存页复制都不需要，因为子进程和父进程共享地址空间，可能会破坏父进程数据。适用于性能敏感场景，尤其是当子进程紧接着调用 `exec()` 启动新程序时。

### clone

clone相比fork()创建的新进程相比，就是它允许灵活创建独立进程或共享资源的线程。

### 实质

fork、vfork、clone在内部实际上都是调用do_fork，只是填写的参数不一样。



## 进程与线程





进程调度：

<img src="img/process-schedule.png" style="zoom: 67%;" />

### 进程控制块（PCB）

- PCB是进程存在的唯一标识
- PCB包含的信息
  - **进程描述信息**：进程标识符，用户标识符。
  - **进程控制和管理信息**：进程当前的状态，优先级
  - **资源分配清单**：内存地址和虚拟地址信息，文件打开列表和I/O信息
  - **CPU相关信息**：CPU中各个寄存器的值



### 进程上下文切换

**CPU上下文切换**：就是先把前⼀个任务的 CPU 上下⽂（**CPU 寄存器和程序计数器**）保存起来，然后加载新任务的上下⽂到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运⾏新任务。

**进程上下文切换**：

当操作系统决定将 CPU 从一个进程切换到另一个进程时，必须保存当前进程的状态，以便在以后某个时候可以恢复并继续执行。这个状态就是进程上下文，它**通常保存在进程控制块（PCB）**。

以下是一些典型的需要保存在 PCB 中的信息：

1. 进程状态：进程当前的运行状态，例如就绪、运行、等待等。
2. 进程标识符：唯一标识一个进程的标识符。
3. **程序计数器**：包含了下一条需要执行的指令地址。
4. **CPU 寄存器**：这些寄存器包括累加器、数据寄存器、地址寄存器、条件码寄存器等。
5. CPU 调度信息：包括进程优先级、调度策略（如轮转、优先级调度等）、CPU 占用时间、其他调度参数等。
6. **内存管理信息**：如页表、段表、内存限制、进程的地址空间信息等。
7. I/O 状态信息：包括 I/O 请求、已分配的 I/O 设备和文件等。

发送进程上下文切换的场景有：

+ 时间片到期
+ 进程系统资源不足，要等到有资源了才能运行，这个时候进程被挂起，调度其他进程
+ 硬件中断，需要中断挂起当前进程，切换到内核中断处理进行
+ 使用sleep主动挂起

### 线程

线程满足一下特性：

- 线程之间共享相同的地址空间
- 实体之间可以并发执行
- 每个线程拥有一套独立的寄存器和栈





### 线程的实现

主要有三种方式：

- **用户线程**：⽤户空间实现的线程，**不是由内核管理的线程**，是由**⽤户态的线程库**来完成线程的管理
  - 优势：
    - 可用于不支持线程技术的操作系统
    - 无需用户态与内核态切换，所以速度特别快
  - 缺点
    - 一个线程因为**系统调用阻塞**，会导致一个进程内所有其它线程的阻塞
    - 除非运行中的线程**主动交出CPU**，否则其它线程无法运行
    - 由于时间片分给进程，所以相较于其它进程，**多线程每个线程得到的时间片更少**
- **内核线程**：在内核中实现的线程，是由**内核管理的线程**
  - 优势：
    - 在⼀个进程当中，如果某个内核线程发起系统调⽤⽽被阻塞，并**不会影响其他内核线程的运⾏**  
    - 分配给线程，多线程的进程获得**更多的 CPU 运⾏时间**
  - 缺点
    - 线程的创建、终⽌和切换都是通过系统调⽤的⽅式来进⾏，因此对于系统来说，**系统开销⽐较⼤**
- **轻量级线程**：是内核支持的用户线程，一个进程可以有多个LWP



### 一个进程能够创建的线程数

​	一个进程可以创建的线程数由可用**虚拟空间**和**线程的栈**的大小共同决定。



## 调度算法

在进程的生命周期中，进程从一个运行状态到另一个运行状态变化的时候，就会触发一次调度。比如:

+ 就绪态->运行态：从就绪队列选一个进程运行
+ 运行态->就绪态：当发生I/O事件的时候
+ 运行态->结束态

1. **先来先服务调度算法**（FCFS）

   算法描述：略

   算法总结：**FCFS 对⻓作业有利**，适⽤于 CPU 繁忙型作业的系统，⽽不适⽤于 I/O 繁忙型作业的系统  

2. **最短作业优先调度算法**（SJF）

   算法描述：优先选择总运行时间最短的进程来运行，有助于提高系统的吞吐率。

   算法总结：对长作业不利，可能导致长作业永远无法被执行。

3. **高响应比优先调度算法**（HRRN）

   算法描述：主要权衡了长短作业，每次调度时需要先计算响应比优先级，然后把响应比优先级最高的进程投入运行。响应比计算公式
   $$
   优先级 = \frac{等待时间 + 要求服务时间}{要求服务时间}
   $$
   算法总结：如果两个进程，等待时间相同，则要求服务时间越短，优先级越高。而长作业随着等待时间的增加也会逐渐提高优先级。

4. **时间片轮转调度算法**（RR）

   算法描述：每个进程分配一个时间段，称位时间片，允许线程在该时间段中运行。如果时间片用完，进程还在运行，那么就会吧这个进程从CPU释放出来，并把CPU分配给另外一个进程。如果进程在时间片内阻塞或者结束了，就CPU立即进行切换。

   算法总结：时间片长度的选择，很重要如果时间片过长，会导致对短作业的响应时间过长，时间片过短导致过多的进程上下文切换。

5. **最高优先级调度算法**

就是给时间片轮转算法加了一个调度优先级

6. **多级反馈队列调度算法**

算法描述：

​	多级：表示有多个队列，每个队列优先级从⾼到低，同时**优先级越⾼时间⽚越短**。

​	反馈：表示如果有新的进程加⼊优先级⾼的队列时，⽴刻停⽌当前正在运⾏的进程，转⽽去运⾏优先级⾼的队列  

·新的进程会被放入到第一级队列的未尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定
的时间片没运行完成，则将其转入到第二级队列的未尾，以此类推，直至完成；
·当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较
高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

### 单核和多核的进程调度有什么不一样

+ 单核只能通过时间片的方式来快速切换模拟”并发“，可以真正实现”并行“处理
+ 单核的上下文切换开销主要是对上下文的保存和回复；而多核还需要考虑缓冲命中率的问题，虽然L3是多个核心之间共享的缓存，但是L1和L2是核心独有的，（所以CPU还提供把线程绑定在一个CPU核心上的方法，比如sched_setaffinity方法。
+ 单核调度比较简单，可以使用RR方法；多核调度需要考虑亲和性和NUMA架构优化
+ 负载均衡问题：对于单核调度只需要把所有任务都在一个CPU排队；而多核调度需要考虑负载均衡任务，放置某一个过于空闲

### linux中就绪队列的数据结构是怎么样的

linux下一般分为了CFS调度器和实时调度器。每个 CPU 核都有自己的调度器和就绪队列（多核系统下是**每核一个运行队列**）。

CFS 的就绪队列使用的是一个**红黑树（Red-Black Tree）**，如下所述：

- 每个**可运行的进程是一个节点**。
- 红黑树按照 `vruntime`（虚拟运行时间）排序，`vruntime` 越小表示被调度的优先级越高。
- 查找、插入、删除操作复杂度都是 **O(log n)**。
- 最左边的节点就是 **当前最“公平”应该运行的进程**，CFS 会选择它。

对于实时调度器：

- 使用 **优先级数组（Priority Array）** 或 **链表数组**。
- 按优先级从高到低查找第一个非空队列。

## 同步与 互斥

「互斥」的作用就是放置多个线程一起进入临界区。「同步」相当于在多线程的场景下，线程之间可能会互相等待消息。

一般使用的工具就是：锁和信号量

使用**锁**可以解决并发进入临界区的问题。锁一般分为了「忙等待锁」和「无忙等待锁」。忙等待锁一般就是自旋锁，依赖CAS机制实现（CAS是原子操作，所谓原子操作就是要么全执行要么都不执行）。这种锁会一直while循环直到锁可用。而另一个就是互斥锁，当线程无法获得锁的时候就会直接让线程休眠，把线程放入等待锁队列，等到锁可用的时候才会重新被调度，尝试再次获得锁。



## 内存页面置换算法

### 最佳页面置换算法

基本思路是，置换在未来最长时间不访问的页面。这个是一个理想算法，一般是用来衡量算法的效率的

### 先进先出置换算法

思想是 **选择驻留在内存时间最长的页面进行置换**。

### LRU

选择最长时间没有被访问的页面进行置换。

### 时钟页面置换算法

它的思路是，把所有页面保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。当发生缺页中断的时候：

+ 如果它的访问位是0就淘汰该页面，并把新页面插入到这里，并把表针前移一个位置。
+ 如果访问位是1就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位位0的页面为止。

### LFU算法

他的思路是，当发送缺页中断的时候，选择 **访问次数**最少的那个页面，并把它淘汰。实现方式是，对每个页面设置一个访问计数器，每当一个页面被访问的时候，该页面访问计数器+1，在发送缺页中断的时候，淘汰计数器值最小的那个页面。



## linux上的缓存预读机制

Linux存在page cache，并不能无限缓存，所以需要频繁访问的数据留在缓存，少访问的可以被淘汰。

最容易想到的是LRU机制，但是传统的LRU算法容易有：

+ 预读失效导致缓存命中率下降
+ 缓存污染导致缓存命中率下降

首先是Linux在读缓存的时候有 **预读机制**，也就是说，应用程序虽然只想读某个范围的数据，但是由于局部性原理，会额外多读数据。但是如果这些提前加载进来的页没有被访问，那么相当于预读工作白做了，就是预读失效。

为了减少这个情况，使用了把数据分为冷数据和热数据，然后分别进行LRU算法管理。

比如Linux操作系统实现了两个LRU链表： 活跃LRU链表与非活跃LRU链表。

+ Active list存放了最近被访问的内存页
+ Inactive list存放的很少被访问的内存页

预读页会被加入到inactive list的头部，只有页真正被访问的时候，才会插入active list头部。如果预读的页一直没被访问就会从inactive lsit移除。

### 缓存污染

缓存污染是读取了大量数据，但是这些数据只会被访问一次，但是它们会占据所有的active list。

可以想到的解决方法是，只要LRU算法被访问一次就加入活跃LRU链表，这种LRU算法进入活跃LRU链表的门槛太低了，所以可以想到的就是：

+ 在内存被访问第二次的时候，才把页从inactive list升级到active list

## 线程间通信方式

### **共享变量**

**全局变量**：两个线程操作同一个全局变量。但是，考虑到线程间可能会同时访问共享变量，通常需要采用**同步机制**（如锁、条件变量）来保护共享变量。

### 条件变量

**条件变量**是线程间通信的一种方式，往往和互斥锁配合使用，允许线程之间通过 wait 和 notify 机制进行同步。通常用于解决生产者-消费者模型中的数据读取和写入问题。

- 一个线程可以等待条件变量上的信号（`std::condition_variable::wait()`），阻塞自己，直到另一个线程通知（`std::condition_variable::notify_one()` 或 `notify_all()`）。
- 搭配互斥锁使用，确保条件检查和操作的原子性。

### **原子变量（std::atomic）**

**原子变量**是线程安全的共享变量，能够在多线程环境中实现无需锁的同步。它通过硬件的原子指令保证操作的原子性，从而避免了传统锁的复杂性和性能开销。

### 消息队列

消息队列是线程间通信的一种经典方式，线程通过队列发送和接收消息来交换信息，完全解耦线程之间的通信。



## 配置中心通信问题

### 客户端是怎么感知到服务端配置发生了变化的呢

数据交互有两种模式：Push（推模式）和 Pull（拉模式）。

+ 推模式指的是客户端与服务端建立好网络长连接，服务方有相关数据，直接通过长连接通道推送到客户端
+ 拉模式指的是客户端主动向服务端发出请求，拉取相关数据。优点是不存在数据堆压，缺点是数据更新不够及时。

如果采取 **拉模式**，那么一般是使用的 **长轮询**，也就是客户端发起一个 `GET /configs/xxx?listen=true` 请求,配置中心不立刻返回，而是**阻塞等待**配置是否变化（如 30 秒超时）；若配置变了，就立即响应给客户端；客户端收到变更后刷新配置，并再次发起监听。

如果是采取 **推模式**，一般客户端启动时，与配置中心通过 **长连接（TCP/gRPC/Netty）** 建立通信，然后拉取一次全量配置。客户端注册感兴趣的配置 key，配置中心维护连接和监听列表，当配置变更，配置中心会**立即主动推送通知**客户端，客户端收到事件，触发本地配置刷新。

就比如zookeeper中的watch()机制，可以注册监听节点。

> Zookeeper 的客户端和服务端通过 **TCP 长连接** 进行通信。客户端在启动时会创建与服务端的连接并保持活跃，服务端通过这个连接发送 **事件通知**，而客户端使用 **异步回调机制**（如事件驱动模型）来接收和处理这些通知。



## 进程间通信（IPC）

### 管道

管道传输数据是单向的。管道有两种：

- **匿名管道**顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中，shell 命令中的「|」竖线就是匿名管道，通信的数据是无格式的流并且大小受限，通信的方式是单向的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来匿名管道是只能用于存在父子关系的进程间通信，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。通过 `pipe()` 创建
- **命名管道**突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。通过 `mkfifo()` 创建



### 消息队列

管道的方式通讯效率低下，不适合频繁的交换数据。

​	消息队列是保存在内核中的消息链表，消息的发送⽅和接收⽅要约定好消息体的数据类型，所以**每个消息体都是固定⼤⼩的存储块**，如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。**消息队列的生命周期随内核**，如果没有释放消息队列，或者没有关闭操作系统，消息队列会一直存在。

​	**消息队列不适合⽐较⼤数据的传输**，因为在内核中每个消息体都有⼀个最⼤⻓度的限制，同时所有队列所包含的全部消息体的总⻓度也是有上限。



### 共享内存

消息队列的读取和写⼊的过程，都会有**发⽣⽤户态与内核态之间的消息拷⻉过程。那共享内存的⽅式，就很好的解决了这⼀问题**。共享内存机制就是拿出一**部分虚拟空间映射到相同的物理内存**。

**实现：**

共享内存的核心在于**将同一块物理内存映射到多个进程的虚拟地址空间**，并保证这些虚拟地址指向相同的物理页面。

- **虚拟内存页面映射：** 每个进程有自己的虚拟地址空间，但操作系统可以让多个进程的虚拟地址指向同一块物理内存。通过修改页表（Page Table），可以让不同的虚拟地址映射到同一物理页。
- 映射的方式：
  - 操作系统在创建共享内存时，会分配一个共享内存段（物理内存块）。
  - 将这块物理内存的地址映射到进程 A 和进程 B 的页表中，从而实现共享。

工作流程：

1. **内存分配：**
   - 一个进程（或操作系统）需要通过系统调用（如 POSIX 的 `shmget` 或 `mmap`）创建一块共享内存。
   - 操作系统从全局物理内存池中分配一段连续的物理内存来作为共享内存段。这段内存有一致的标识符（类似于文件系统的文件描述符）。
2. **页表建立和维护：**
   - 操作系统为创建共享内存的进程将这段物理内存映射到其虚拟地址空间，通过内存页表实现虚拟地址和物理地址的对应关系。
   - 当其他进程请求访问该共享内存时，操作系统会将那段物理内存**映射到其它进程的地址空间**，并复制页表对应的映射。
3. **访问与权限管理：**
   - 内核会为共享内存段分配一个唯一的标识符（如 POSIX 的 `key_t` 或 Linux 中的 `/dev/shm` 文件）。
   - 每次访问共享内存时，进程需要指定该标识符，内核会检查进程的访问权限是否符合共享内存的设定（如读、写权限）。
   - 如果权限正确，操作系统允许进程访问该共享内存。
4. **数据同步：**
   - 在多个进程同时访问共享内存时，操作系统不会自动提供锁或互斥机制。用户需要借助额外的同步工具（如信号量、条件变量或其他锁）来避免并发问题。

### 以调用mmap举例

当你调用 `mmap()` 时，**内核在用户空间为你分配一段连续的虚拟地址区间**；

这些地址初始并不映射实际物理页，直到你**第一次访问该页**，才通过页错误（page fault）：

- 从文件中加载对应页数据；
- 映射到实际的物理内存页（通过页表）；
- 并建立虚拟地址 ↔ 物理地址的映射关系。

而且mmap也不会立刻把整个文件读入到物理内存，当访问到某个页的时候通过page fault

### 信号量

使用共享内存机制，需要通过信号量来保护共享内存的读写，防止数据竞争。

信号量通常用于线程间的同步和资源共享的限制。如果有一定数量的资源需要在线程之间共享，可以使用信号量来限制对资源的并发访问。

### Socket

使用本地字节流Socket通讯，于普通的TCP通讯的区别在于，`bind`函数调用时，绑定的是一个本地文件。



### 各种通讯方式的比较

1. **管道 (Pipe)**

   **优势**：

   - 管道是最**简单**的IPC方式之一，因此在实现上相对简单。
   - 管道可以在父子进程间创建，也可以通过命名管道在不相关的进程间进行通信。
   - 管道在进程间提供了一种顺序的、固定大小的缓冲区，这对于控制数据流非常有用。

   **缺点**：

   - 管道是**半双工**的，数据只能在一个方向上流动；如果需要双向通信，就需要两个管道。
   - 管道的**容量有限**，如果管道满了，写操作会被阻塞；如果管道空了，读操作会被阻塞。
   - 管道**不适合大量数据的传输**，因为它们需要在**内核空间和用户空间之间复制数据**。

2. **消息队列 (Message Queue)**

   **优势**：

   - 消息队列允许进程以消息的形式进行通信，**每个消息都有一个类型，进程可以根据类型读取消息**。
   - 消息队列是独立于发送和接收进程的，因此**即使发送进程崩溃，消息仍然可以被接收进程读取**。
   - 消息队列可以**实现复杂的通信模式，如发布/订阅等**。

   **缺点**：

   - 消息队列的操作（发送、接收、控制）可能比较复杂。
   - **消息队列的大小有限**，如果队列满了，发送操作会被阻塞。
   - 消息队列需要在**内核空间和用户空间之间复制数据**，这可能会影响性能。

3. **共享内存 (Shared Memory)**

   **优势**：

   - 共享内存是**最快的IPC方式**，因为它允许多个进程访问同一块物理内存。
   - 共享内存可以**容纳大量的数据**，只受制于系统的物理内存大小。
   - 共享内存**避免了在内核空间和用户空间之间复制数据**，因此性能很高。

   **缺点**：

   - 共享内存需要进程**自己进行同步**，否则可能会导致数据的不一致性。
   - 共享内存的管理（创建、连接、分离、删除）相对复杂。
   - 如果一个进程崩溃，它**可能会留下一块无人管理的共享内存**，这可能会导致资源泄露。



### Linux上各种通讯机制的接口

1. **管道（Pipe）和命名管道（Named pipe）**
    - `int pipe(int pipefd[2]);` 创建一个新的管道，`pipefd[0]`用于读，`pipefd[1]`用于写。
    - `int mkfifo(const char *pathname, mode_t mode);` 创建一个新的命名管道，`pathname`是命名管道的路径，`mode`用于设置命名管道的权限。

2. **信号（Signal）**
    - `typedef void (*sighandler_t)(int);`
    - `sighandler_t signal(int signum, sighandler_t handler);` 为指定的信号`signum`设置信号处理函数`handler`。

3. **消息队列（Message Queue）**
    - `int msgget(key_t key, int msgflg);` 创建新的消息队列或获取已存在的消息队列，`key`是消息队列的键，`msgflg`用于设置消息队列的权限和创建选项。
    - `int msgsnd(int msqid, const void *msgp, size_t msgsz, int msgflg);` 向消息队列`msqid`发送消息，`msgp`指向要发送的消息，`msgsz`是消息的大小，`msgflg`是发送选项。
    - `ssize_t msgrcv(int msqid, void *msgp, size_t msgsz, long msgtyp, int msgflg);` 从消息队列`msqid`接收消息，`msgp`指向接收到的消息，`msgsz`是消息的大小，`msgtyp`用于指定要接收的消息类型，`msgflg`是接收选项。

4. **共享内存（Shared Memory）**
    - `int shmget(key_t key, size_t size, int shmflg);` 创建新的共享内存或获取已存在的共享内存，`key`是共享内存的键，`size`是共享内存的大小，`shmflg`用于设置共享内存的权限和创建选项。
    - `void *shmat(int shmid, const void *shmaddr, int shmflg);` 将共享内存`shmid`附加到进程的地址空间，`shmaddr`是附加的地址，`shmflg`是附加选项。
    - `int shmdt(const void *shmaddr);` 将共享内存从进程的地址空间分离，`shmaddr`是分离的地址。

5. **信号量（Semaphore）**
    - `int semget(key_t key, int nsems, int semflg);` 创建新的信号量或获取已存在的信号量，`key`是信号量的键，`nsems`是信号量的数量，`semflg`用于设置信号量的权限和创建选项。
    - `int semop(int semid, struct sembuf *sops, size_t nsops);` 对信号量`semid`进行操作，`sops`是操作数组，`nsops`是操作数量。

6. **套接字（Socket）**
    - `int socket(int domain, int type, int protocol);` 创建一个新的套接字，`domain`指定协议族，`type`指定套接字类型，`protocol`指定协议。
    - `int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);` 将套接字`sockfd`绑定到地址`addr`，`addrlen`是地址的长度。
    - `int listen(int sockfd, int backlog);` 使套接字`sockfd`进入监听状态，`backlog`是等待连接队列的最大长度。
    - `int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);` 接受套接字`sockfd`的连接请求，`addr`是连接的地址，`addrlen`是地址的长度。
    - `int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);` 连接到套接字`sockfd`，`addr`是连接的地址，`addrlen`是地址的长度。
    - `ssize_t send(int sockfd, const void *buf, size_t len, int flags);` 向套接字`sockfd`发送数据，`buf`是数据缓冲区，`len`是数据长度，`flags`是发送选项。
    - `ssize_t recv(int sockfd, void *buf, size_t len, int flags);` 从套接字`sockfd`接收数据，`buf`是数据缓冲区，`len`是数据长度，`flags`是接收选项。



### 在Linux系统上查看IPC

在Linux系统中可以通过`ipcs`命令查看当前系统中的进程间通信情况。

| IPC对象          | 命令       | 描述                                                 |
| ---------------- | ---------- | ---------------------------------------------------- |
| 共享内存         | `ipcs -m`  | 显示当前存在的所有共享内存段                         |
| 共享内存（详细） | `ipcs -mp` | 显示共享内存的详细信息，包括创建者和最后操作的进程ID |
| 消息队列         | `ipcs -q`  | 显示当前存在的所有消息队列                           |
| 消息队列（详细） | `ipcs -qp` | 显示消息队列的详细信息，包括创建者和最后操作的进程ID |
| 信号量           | `ipcs -s`  | 显示当前存在的所有信号量                             |
| 信号量（详细）   | `ipcs -sp` | 显示信号量的详细信息，包括创建者和最后操作的进程ID   |



## 僵尸进程与孤儿进程

僵尸进程（Zombie Process）和孤儿进程（Orphan Process）是操作系统中的两种不同状态的进程。

1. 僵尸进程（Zombie Process）：
   - 僵尸进程是指一个已经终止执行的进程，但其父进程尚未调用`wait()`或`waitpid()`系统调用来获取其终止状态。
   
   > 这样的话，子进程的PCB没有被回收，导致进程表依然有其PCB占用系统资源，此时进程状态是Z。太多的僵尸进程会使得无法创建新进程，拖慢系统速度。
   
   - 当一个进程终止时，操作系统会将其进程控制块保留在系统中，直到父进程通过`wait()-阻塞`或`waitpid()--可以设置为非阻塞`来获取其终止状态。还有个办法就是**终止父进程**，使得僵尸进程被init接管来释放；还有个办法父进程注册SIGCHILD信号，通过回调函数调用wait,waitpid 
   - 僵尸进程不占用系统资源，但它们的存在表明父进程没有正确处理子进程的终止状态，可能是因为父进程已经终止或者出现了其他问题。
   - 当父进程获取到僵尸进程的终止状态后，操作系统会释放僵尸进程的资源，并从系统中删除其进程控制块。
   
2. 孤儿进程（Orphan Process）：
   - 孤儿进程**是指其父进程提前终止**，而子进程尚未终止的进程。由于在linux中子进程的资源回收是由父进程负责的，于是如果父进程终止了，就会移交给init进程。
   - init进程是 **操作系统第一个启动的用户态进程，用户态的进程都是直接或间接由init派生而来**
   - 当父进程终止时，操作系统会将孤儿进程的父进程设置为init进程（进程ID为1）。
   - init进程会接管孤儿进程，并成为其新的父进程，负责回收其终止状态。
   - 孤儿进程不会成为僵尸进程，因为它们的父进程（即init进程）会及时处理它们的终止状态。
   - 一旦孤儿进程终止，其终止状态会被init进程获取并释放相关资源。

综上所述，**僵尸进程是指已经终止但父进程尚未处理终止状态的进程，而孤儿进程是指父进程提前终止而子进程尚未终止的进程。**



### 如何避免产生僵尸进程

要避免僵尸进程的产生，可以采取以下几种方法：

1. 父进程调用`wait()`或`waitpid()`系统调用：父进程在fork子进程后，应该及时调用`wait()`或`waitpid()`系统调用来获取子进程的终止状态。这样可以确保子进程的资源被及时释放，避免僵尸进程的产生。
2. 使用信号处理机制：父进程可以通过注册信号处理函数来捕获子进程的终止信号（如SIGCHLD信号）。当父进程接收到该信号时，可以调用`wait()`或`waitpid()`来处理子进程的终止状态。
3. **设置子进程的信号处理方式**：在子进程中，可以通过调用`signal()`函数来设置子进程终止时的信号处理方式。**可以将子进程的终止信号设置为SIG_IGN**，表示在子进程终止时忽略该信号，这样子进程就不会变成僵尸进程。
4. 使用守护进程（Daemon Process）：守护进程是一种在后台运行的进程，通常没有控制终端。守护进程会通过调用`fork()`创建子进程，并在子进程中调用`setsid()`函数创建一个新的会话。这样，父进程会立即终止，而子进程成为一个新的会话领导者。由于守护进程没有控制终端，也没有父进程来获取其终止状态，因此守护进程不会产生僵尸进程。



## 守护进程

守护进程（Daemon）是一种在后台运行的特殊进程，独立于控制终端。它们通常在系统引导装载时启动，并且一直运行到系统关闭。常见的守护进程有网络服务（如HTTP服务器和邮件服务器）和系统任务（如定时任务调度器cron）。

创建一个守护进程需要以下步骤：

1. **创建孤儿进程**：这通常通过在父进程中调用`fork()`并退出父进程来完成。这样子进程就成为一个孤儿进程，其父进程是init或者systemd（PID为1的进程）。

2. **在子进程中创建新的会话**：调用`setsid()`创建新的会话并成为会话的领导。这样子进程就不会受到任何终端的控制。

3. **改变当前工作目录**：将当前工作目录改为根目录，调用`chdir("/")`。这是因为守护进程可能在任何文件系统中打开文件，如果不改变工作目录，那么该文件系统就不能被卸载。

4. **重设文件权限掩码**：调用`umask(0)`来清除文件模式创建掩码，防止继承的文件权限可能导致的问题。

5. **关闭文件描述符**：守护进程不应从终端读取或写入。因此，需要关闭所有打开的文件描述符（包括stdin，stdout，stderr）。你也可以将它们重定向到/dev/null。

以下是一个简单的C语言创建守护进程的示例：

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <signal.h>

void daemonize() {
    pid_t pid;
    
    // Step 1: Fork the Parent Process
    pid = fork();

    if (pid < 0) exit(EXIT_FAILURE);
    if (pid > 0) exit(EXIT_SUCCESS);

    // Step 2: Create a new Session
    if (setsid() < 0) exit(EXIT_FAILURE);

    // Step 3: Catch, Ignore and Handle Signals
    // Implement code to ignore signals or handle them as needed

    // Step 4: 这里再次Fork防止子进程再次打开终端
    pid = fork();

    if (pid < 0) exit(EXIT_FAILURE);
    if (pid > 0) exit(EXIT_SUCCESS);

    // Step 5: Change Directory to Root
    chdir("/");

    // Step 6: Close Standard File Descriptors
    close(STDIN_FILENO);
    close(STDOUT_FILENO);
    close(STDERR_FILENO);

    // Daemon-specific initialization goes here
}

int main() {
    daemonize();

    // The Big Loop
    while (1) {
        sleep(30); // wait 30 seconds
        // Do some task here ...
    }

    exit(EXIT_SUCCESS);
}
```



## 终端退出

在Linux中，如果你在终端启动了一个进程，然后退出了终端，那么这个进程通常会收到一个**SIGHUP（hang up）**信号，导致该进程终止。这是因为这个进程是作为终端的一个子进程运行的，当终端退出时，所有的子进程都会收到这个SIGHUP信号。

但是，有一些方法可以让进程在终端退出后继续运行：

1. 使用 `nohup` 命令：`nohup` 是 "no hang up" 的缩写，这个命令可以使得在终端退出后进程继续运行。例如，`nohup myprogram &` 将在后台启动 `myprogram` 并忽略所有SIGHUP信号。

2. 使用 `screen` 或 `tmux`：这些程序可以创建一个或多个独立于终端的会话，这样即使终端被关闭，这些会话也会继续运行。

3. 使用 `disown` 命令：如果你已经在一个bash shell中启动了一个后台进程，你可以使用 `disown` 命令来移除这个进程与终端的关联，这样当终端关闭时，这个进程也不会收到SIGHUP信号。例如，如果你已经启动了一个后台进程，你可以通过运行 `disown %1` （这里的1是你的进程的job ID）来移除这个进程与终端的关联。



## 死锁

### 死锁的条件

死锁（Deadlock）是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。以下是产生死锁的四个必要条件：

1. **互斥条件（Mutual Exclusion）**：一个资源每次只能被一个进程使用。即在一段时间内，某资源仅为一个进程所占有，此时若有其他进程请求该资源，则必须等待，直至占有该资源的进程使用完毕。

2. **请求和保持条件（Hold and Wait）**：一个进程因请求资源而阻塞时，对已获得的资源保持不放。也就是说，进程至少已经持有一个资源，但又申请新的资源；因为该资源已被其他进程占有，此时该进程阻塞，但是对自己已获得的资源不释放。

3. **非剥夺条件（No Preemption）**：进程已获得的资源，在未使用完之前，不能被其他进程强行剥夺，只能由该进程自己释放。

4. **循环等待条件（Circular Wait）**：存在一个进程资源的循环等待链，链中每一个进程已获得的资源同时被链中下一个进程所请求。即，存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被链中下一个进程所需。

只有当这四个条件同时满足时，才会发生死锁。如果系统中去掉了这四个条件中的任何一个，就可以防止死锁。

### 避免死锁

前面说了出现死锁必须同时满足这4个条件，所以为了避免死锁，就打破一个条件就可以：

1. 打破占有且等待状态： 设置一个超时机制，当一段时间内尝试加锁，超时后就放弃操作。
2. 打破循环等待： 规定资源的申请顺序，确保每个线程都按一致的顺序申请资源；或者如果一个线程需要多个资源，必须一次性申请所有资源，而不能逐个申请。

### 预防死锁

死锁检测可以用类似银行家算法的思路，通过模拟资源分配来判断是否有进程永远无法完成。

操作系统会维护每个进程的已分配资源、还需要的资源，以及系统的可用资源。算法会不断尝试满足某些进程的需求，让它们完成并释放资源。如果最后还有进程始终得不到满足，那说明这些进程已经发生了死锁。

> **维护三个核心信息**
>
> - `Available`：当前可用资源数。
> - `Allocation`：每个进程已分配的资源。
> - `Request`：每个进程还需要的资源。
>
> **尝试寻找可满足的进程**
>
> - 在当前 `Available` 资源下，看是否存在某个进程的 `Request <= Available`。
> - 如果有，假设该进程顺利完成，释放它占有的资源回到 `Available`。
>
> **不断迭代**
>
> - 重复这个过程，把能完成的进程一个个“移出队列”。
>
> **判断是否死锁**
>
> - 如果最终还有进程始终无法被满足 → 这些进程就陷入了死锁。





### CAS

CAS叫做compare-and-swap，是一个底层的原子操作。CAS的核心思想是是通过比较共享变量的当前值与预期值，如果当前值等于预期值，就将其更新为一个新值。这整个过程是一个不可分割的原子操作。

伪代码如下:

```
地址（ptr）：操作的目标内存地址。
预期值（expected）：希望变量原来的值应该是预期值。
新值（desired）：如果预期值与变量当前值相等，变量将被更新为该值。


流程：
1.对比共享变量的当前值与 expected（预期值）。
2.如果共享变量的当前值与 expected 相等，则写入 desired（新值）。
3.如果当前值与 expected 不相等，则什么都不做。

function CAS(ptr, expected, desired):
if *ptr == expected:
    *ptr = desired
    return true   // 交换成功
else:
    return false  // 交换失败
```

CAS 的应用场景

**1. 无锁并发编程**

CAS 是无锁并发编程的核心工具。相比锁（`mutex`），CAS 避免了线程间的阻塞，因此更加高效。它通常用于实现无锁队列、栈等数据结构。

**2. 原子变量**

CAS 是实现原子变量的基础，例如：

- `std::atomic`（C++ 标准库提供的原子操作支持）。
- Java 中的 `AtomicInteger` 等类。

**3. 乐观锁**

CAS 的机制与乐观锁的思想一致：假设资源不会发生冲突，在操作完成时通过 CAS 验证资源是否被其他线程修改。如果验证失败，重试操作。

**ABA 问题：**

- 如果共享变量经历了这样的变化：从 A 到 B，再回到 A，CAS 会误认为值没有改变，因此可能导致逻辑错误。
- 解决方法：
  - 使用版本号（如某些程序的操作将值和版本号捆绑在一起）。



## 常见的锁

操作系统中的锁通常用于同步和互斥，常见的锁有：

1. 互斥锁（Mutex）：互斥量(mutex)从本质上说是一把锁，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量上的锁。对互斥量进行加锁以后，任何其他试图再次对互斥锁加锁的线程将会阻塞直到当前线程释放该互斥锁。如果释放互斥锁时有多个线程阻塞，所有在该互斥锁上的阻塞线程都会变成可运行状态，第一个变为运行状态的线程可以对互斥锁加锁，其他线程将会看到互斥锁依然被锁住，只能回去再次等待它重新变为可用。 

1. 条件变量（Condition Variables）：条件变量(cond)是在多线程程序中用来实现"等待--》唤醒"逻辑常用的方法。条件变量利用线程间共享的全局变量进行同步的一种机制，主要包括两个动作：一个线程等待"条件变量的条件成立"而挂起；另一个线程使“条件成立”。为了防止竞争，条件变量的使用总是和一个互斥锁结合在一起。线程在改变条件状态前必须首先锁住互斥量，函数pthread_cond_wait把自己放到等待条件的线程列表上，然后对互斥锁解锁(这两个操作是原子操作)。在函数返回时，互斥量再次被锁住。 

1. 自旋锁（Spinlock）：自旋锁通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。一般加锁的过程，包含两个步骤：第一步，查看锁的状态，如果锁是空闲的，则执行第二步；第二步，将锁设置为当前线程持有；使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。CAS 函数就把这两个步骤合并成一条硬件级指令，形成原子指令，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。这里的「忙等待」可以用 while 循环等待实现，不过最好是使用 CPU 提供的 PAUSE 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。 

1. 信号量（Semaphores）：信号量可以是命名的（有名信号量）或无名的（仅限于当前进程内的线程），用于控制对资源的访问次数。通常信号量表示资源的数量，对应的变量是一个整型（sem）变量。另外，还有两个原子操作的系统调用函数来控制信号量的，分别是：P 操作：将 sem 减 1，相减后，如果 sem < 0，则进程




### 除了互斥锁你还知道什么锁？分别应用于什么场景？

 还有读写锁、自旋锁、条件变量、信号量。  

读写锁：读写锁允许多个线程同时读取共享资源，但只允许一个线程进行写操作。适用于读操作频繁、写操作较少的场景，可以提高并发性能。 

自旋锁：自旋锁是一种忙等待锁，线程在获取锁时不会进入阻塞状态，而是循环忙等待直到获取到锁。适用于临界区很小且锁的持有时间很短的场景，避免线程频繁切换带来的开销。 

条件变量：条件变量用于线程间的同步和通信。它通常与互斥锁一起使用，线程可以通过条件变量等待某个条件满足，当条件满足时，其他线程可以通过条件变量发送信号通知等待线程。

 信号量：信号量是一种计数器，用于控制对共享资源的访问。它可以用来限制同时访问资源的线程数量，或者用于线程间的同步。

### 悲观锁与乐观锁

就是说**悲观锁**做事比较悲观，它认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁。

**乐观锁**做事比较乐观，它假定冲突的概率很低，它的工作方式是：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。

### 无锁并发

无锁并发主要是通过设计，避免使用传统锁实现共享资源的访问。利用CAS这个核心原子操作，可以实现无锁数据结构。

#### 无锁队列

比如要实现一个基于CAS操作的无锁队列，对于入队操作:

```c++
void enqueue(int val) {
        Node* newNode = new Node(val);
        Node* oldTail; //记录老的队尾

        do {
            oldTail = tail.load();       // 获取当前尾
        } while (!tail.compare_exchange_weak(oldTail, newNode)); // CAS 更新尾指针

        oldTail->next = newNode;         // 连接新节点
    }
```

### 操作系统底层如何实现锁

锁的实现依赖原子指令，比如**Test-and-Set**，**Compare-and-Swap（CAS）**，**Fetch-and-Add**

比如实现自旋锁，就可以使用CAS这样的原子指令

如果是互斥锁，在用户态通过原子操作尝试加锁，失败后陷入 **内核态阻塞**，让出CPU，等待调度唤醒。在linux中底层互斥锁使用 **futex（快速用户态互斥量）** 实现，它允许线程：

- 成功时：在**用户态原子操作完成加锁**。
- 失败时：通过 `futex()` 系统调用将自己**挂起**等待。

# 文件系统相关

## 磁盘调度算法

磁盘寻道算法是操作系统用来决定硬盘的读写头应该如何移动以处理磁盘请求队列的一种算法。这些算法的**目标是尽量减少磁头的移动，从而减少寻道时间，提高磁盘的效率。**以下是一些常见的磁盘寻道算法：

1. 先来先服务（FCFS，First-Come-First-Serve）：这是最简单的一种算法，按照请求的到达顺序进行服务。但是这种算法可能会导致磁头移动距离较大，效率不高。

2. 最短寻道时间优先（SSTF，Shortest Seek Time First）：这种算法选择当前磁头位置最近的请求进行服务。这种方法比FCFS效率更高，但可能会导致一些距离磁头始终较远的**请求可能会被无限期地推迟**。

3. 扫描算法（SCAN）：在这种算法中，磁头从一端移动到另一端，服务所有在其路径上的请求，然后反向移动，如此往复。这种算法也被称为电梯算法，因为它的行为类似于电梯在楼层之间上下移动。

4. 循环扫描（C-SCAN）：这种算法是SCAN的一种变体。在扫描到一端后，磁头直接返回到另一端，然后再开始扫描。这种方式可以提供**更公平的服务**，因为每个请求的等待时间最多为一次完整的扫描时间。

5. LOOK和C-LOOK：这是SCAN和C-SCAN的改进版，磁头**在没有请求的方向上不会继续移动，只在有请求的方向上移动**。



## 文件系统基本组成

​	Linux ⽂件系统会为每个⽂件分配两个数据结构： **索引节点（index node）**和**⽬录项（directory entry）** ，它们主要⽤来记录⽂件的元信息和⽬录层次结构  

### 索引结点

索引节点，也就是 inode，⽤来**记录⽂件的元信息**，⽐如 inode 编号、⽂件⼤⼩、访问权限、创建时间、修改时间、 数据在磁盘的位置等等。索引节点是⽂件的唯⼀标识，会被**存储在磁盘中，占用磁盘空间**。



### 目录项

⽬录项，也就是 dentry，⽤来**记录⽂件的名字、 索引节点指针以及与其他⽬录项的层级关联关系**。多个⽬录项关联起来，就会形成⽬录结构，但它与索引节点不同的是， **⽬录项是由内核维护的⼀个数据结构，不存放于磁盘，⽽是缓存在内存**。



### 目录项和索引结点的关系

在Linux文件系统中，目录项（Directory Entry）和索引节点（Inode，Index Node）是两个核心概念，它们共同构建了文件系统的基础结构。

1. 目录项（Directory Entry）：目录项是文件系统中的一个实体，它包含了文件名和对应的索引节点号。目录项的主要作用是提供一个映射，**将用户可识别的文件名映射到文件系统内部的索引节点**。

2. 索引节点（Inode）：索引节点是文件系统中的另一个实体，它包含了关于文件的所有信息，如文件类型（普通文件、目录、字符设备、块设备等）、权限、所有者、大小、访问和修改时间等。此外，它还包含了一组指针，这些指针指向存储文件数据的磁盘块。但是，索引节点并不包含文件名，文件名是存储在目录项中的。

目录项和索引节点的关系可以这样理解：用户通过文件名访问文件，文件系统通过目录项找到对应的索引节点号，然后通过索引节点号找到索引节点，获取文件的元数据和数据块的位置，最后从磁盘上读取或写入数据。**这种设计方式允许在不同的目录下创建指向同一索引节点的链接，也就是所谓的硬链接**，实现了文件的共享。

<img src="./img/inode-entry.png" style="zoom:67%;" />





### 目录项和目录

虽然名字很相近，但是它们不是⼀个东⻄，**⽬录是个⽂件，持久化存储在磁盘，⽽⽬录项是内核⼀个数据结构，缓存在内存**。

内核会把已经读过的⽬录⽤⽬录项这个数据结构缓存在内存，下次再次读到相同的⽬录时，只需从内存读就可以，⼤⼤提⾼了⽂件系统的效率。



### 磁盘分区

磁盘进⾏格式化的时候，会被分成三个存储区域，分别是**超级块**、**索引节点区**和**数据块区**  。

文件系统的组成主要包括以下三个部分：超级块(Superblock)、索引节点区(Inode Table)和数据块区(Data Block)。

1. **超级块（Superblock）**：超级块是**文件系统的元数据**，包含了文件系统的重要信息，如文件系统的大小、空闲和已使用的数据块和inode数量、最后一次挂载、校验等信息。超级块对于文件系统的操作至关重要，因此通常会在多个地方备份超级块。

2. **索引节点区（Inode Table）**：在Unix和类Unix系统中，每个文件或目录都有一个与之关联的索引节点，或称为inode。inode包含了关于**文件的元数据**，如文件大小、访问权限、创建和修改时间、数据块的位置等。**inode不包含文件名和文件数据**，**文件名存储在目录的数据块中，文件数据存储在数据块中**。

3. **数据块区（Data Block）**：数据块是文件系统存储文件数据的地方。每个文件的数据都被分割成一系列的数据块，这些数据块可能是连续的，也可能是分散的。数据块的大小通常是固定的，例如1KB、2KB、4KB等，这个大小是在创建文件系统时确定的。数据块除了存储文件数据外，还用于存储目录信息，例如文件名和对应的inode号。



## 虚拟文件系统

虚拟文件系统（Virtual File System，简称VFS）是操作系统的内核中的一个接口，**它为应用程序提供了一个统一的视图来访问各种不同类型的文件系统。**VFS的目标是**使应用程序能够在不关心底层文件系统类型的情况下，对文件系统进行访问和操作**。

VFS提供了一个抽象层，使得所有的文件系统看起来都像是同一种类型。这意味着，无论文件实际上是存在于硬盘上的EXT4文件系统，还是网络上的NFS文件系统，或者是内存中的tmpfs文件系统，对于应用程序来说，都是通过相同的接口和方式进行访问。

在Linux中，VFS是非常重要的一部分。它不仅支持传统的磁盘文件系统，如EXT4、Btrfs等，还支持各种网络文件系统，如NFS、SMB等，以及特殊的文件系统，如procfs（用于访问内核和进程状态信息）、sysfs（用于访问和控制设备）、tmpfs（用于存储临时文件）等。这些都是通过VFS的抽象接口实现的。

在Linux的VFS中，所有的文件和目录都是以一个称为inode（索引节点）的数据结构来表示的。每个inode包含了文件或目录的元数据，如权限、所有者、大小、创建和修改时间等。VFS通过这些inode来进行文件的查找、读取、写入等操作。

总的来说，VFS在操作系统中起到了桥梁的作用，使得应用程序可以透明地访问各种不同的文件系统，而无需关心其底层的实现细节。



## 文件的存储

⽂件的数据是要存储在硬盘上⾯的，数据在磁盘上的存放⽅式，就像程序在内存中存放的⽅式那样，有以下两种 ：

- 连续空间存放方式
- 非连续空间存放方式

其中，⾮连续空间存放⽅式⼜可以分为「链表⽅式」和「索引⽅式」

### 连续空间存放方式

连续空间存放方式：就是将⽂件存放在磁盘「连续的」物理空间中。

**优点**：

- 读写效率高（只需要一次磁盘寻道）



**缺点**

- 磁盘空间碎片化
- 文件长度不易扩展



### 非连续空间存放

#### 链表方式



#### 索引方式

