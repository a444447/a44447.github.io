---
title: "Cnn_visualization"
date: 2023-08-10T19:27:09+08:00
categories: [æ·±åº¦å­¦ä¹ å…¥é—¨, cs231n]
draft: true
---



è¿™éƒ¨åˆ†æ˜¯åœ¨å­¦ä¹  `cs231n`çš„ã€Œnet visualizationã€éƒ¨åˆ†çš„ä¸€äº›è®°å½•ã€‚

## å¼•å…¥

åœ¨å­¦ä¹ CNNçš„æ—¶å€™ï¼Œæˆ‘ä»¬æœ‰æ—¶å€™ä¸æ˜¯åªå…³å¿ƒæœ€åè¾“å‡ºçš„ç»“æœ(æ¯”å¦‚åˆ†ç±»é—®é¢˜ä¸­ï¼Œæœ€åå°†ä¼šè¾“å‡ºä¸€ä¸ªè¾“å…¥çš„ç±»åˆ«æˆ–è€…æ¦‚ç‡)ã€‚ä½†æ˜¯æœ‰å¾ˆå¤šæ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿæƒ³çŸ¥é“ä¸­é—´çš„é‚£äº›å·ç§¯å±‚å‘ç”Ÿäº†ä»€ä¹ˆï¼Œæ¯ä¸ªå·ç§¯æ ¸åšäº†ä»€ä¹ˆï¼Œæˆ–è€…å®ƒä»¬æ‰¾çš„ç‰¹å¾åˆ°åº•æ˜¯ä»€ä¹ˆã€‚









## æ¢¯åº¦ä¸Šå‡çš„å¯è§†åŒ–å·ç§¯ç¥ç»ç½‘ç»œ

cs231nä¸­ï¼Œè¿™éƒ¨åˆ†çš„ä»‹ç»æ˜¯:

> By starting with a random noise image and performing gradient ascent on a target class, we can generate an image that the network will recognize as the target class. 

ä¹Ÿå°±æ˜¯ï¼Œ**ä»ä¸€ä¸ªéšæœºçš„å™ªéŸ³å›¾ç‰‡å‡ºå‘ï¼Œé€šè¿‡æ¢¯åº¦ä¸Šå‡çš„æ–¹æ³•æ¥è®©æå‡å™ªéŸ³imageçš„åˆ†æ•°ï¼Œç›´åˆ°æˆ‘ä»¬çš„ç½‘ç»œä¼šå°†å®ƒè¯†åˆ«ä¸ºç›®æ ‡ç±»åˆ«**ã€‚å¦å¤–å¦‚æœæˆ‘ä»¬æƒ³è¦æŸ¥çœ‹ *æŸå·ç§¯å±‚æŸå·ç§¯æ ¸ã€Œæƒ³è¦å¯»æ‰¾çš„ç‰¹å¾ã€*,ä¹Ÿå¯ä»¥ç”¨æ¢¯åº¦ä¸Šå‡çš„æ–¹æ³•ã€‚

### class visualization

é¦–å…ˆï¼Œæˆ‘ä»¬æ¥çœ‹`cs231n `ä½œä¸šä¸­è®¾è®¡çš„class visualization.å®šä¹‰ $s_y(I)$, $I$è¡¨ç¤ºç”Ÿæˆçš„å™ªéŸ³Imageï¼Œæˆ‘ä»¬ä¹Ÿæ˜¯è¦åœ¨è¿™å¼ å›¾ä¸Šæ›´æ–°å®ƒçš„pixelsã€‚æˆ‘ä»¬æœ€ç»ˆæƒ³è¦å¾—åˆ°çš„å°±æ˜¯ $I'$â€”â€”$I'$è¾“å…¥ç½‘ç»œåå°†åœ¨æˆ‘ä»¬çš„é€‰æ‹©çš„ç›®æ ‡ç±»åˆ«`target_y`ä¸Šæ‹¥æœ‰è¾ƒé«˜çš„å¾—åˆ†ã€‚ä¸Šé¢çš„è¿™æ®µæè¿°å¯ä»¥ç”¨ä¸‹é¢çš„å…¬å¼è¡¨ç¤º:
$$
I' = arg\underset {I}{max}(s_y(I) - R(I))
$$
å…¶ä¸­

---

åˆå§‹çš„$I$æ˜¯ä¸€ä¸ªå……æ»¡å™ªéŸ³çš„å›¾åƒï¼Œå› æ­¤å®ƒåœ¨ç›®æ ‡åˆ†ç±»`target_y`ä¸Šçš„å¾—åˆ†æ˜¯å¾ˆä½çš„ï¼Œä¸ºäº†å¾—åˆ†å¢åŠ ï¼Œæˆ‘ä»¬åº”è¯¥åšçš„å°±æ˜¯æ›´æ–°$I$ä¸­æ¯ä¸ªpixelsçš„å€¼ã€‚å¦‚ä½•ä¿è¯æˆ‘ä»¬æ¯æ¬¡æ›´æ–°pixelsçš„å€¼éƒ½ä¼šè®©å®ƒæœç€ä½¿å¾—åˆ†å¢åŠ å‘¢ï¼Ÿå¾ˆå®¹æ˜“æƒ³åˆ°çš„å°±æ˜¯ **æ¢¯åº¦**ï¼Œæˆ‘ä»¬åº”è¯¥é¡ºç€æ¢¯åº¦çš„æ–¹å‘æ›´æ–°æˆ‘ä»¬çš„pixelsçš„å€¼ã€‚

{{< notice note >}}

åœ¨ä¸€èˆ¬çš„ç¥ç»ç½‘ç»œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡lossæ¥è¡¡é‡å‚æ•°çš„å¥½åï¼Œå‚æ•°åº”è¯¥æœç€ä½¿lossä¸‹é™çš„æ–¹å‘å‰è¿›ï¼Œä¹Ÿå°±æ˜¯é€†ç€æ¢¯åº¦ã€‚è€Œåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥å°†åœ¨`target_y`ä¸Šçš„å¾—åˆ†çœ‹ä½œæˆ‘ä»¬è¡¡é‡pixelsçš„å¥½åçš„æ ‡å‡†ï¼Œè€Œè¿™æ¬¡æˆ‘ä»¬ä¸æƒ³è®©å®ƒä¸‹é™ï¼Œè€Œæ˜¯è®©å®ƒä¸Šå‡ï¼Œå› æ­¤æˆ‘ä»¬è¦é¡ºç€æ¢¯åº¦ã€‚

{{< /notice >}}

æ ¹æ®ä¸Šé¢çš„æ€è·¯ï¼Œå°±å¾ˆå¥½è¿›è¡Œä»£ç çš„ç¼–å†™ã€‚

é¦–å…ˆæˆ‘ä»¬éœ€è¦åˆå§‹åŒ–ä¸€ä¸ªéšæœºå™ªéŸ³å›¾ç‰‡ã€‚

```python
img = torch.randn(1, 3, 224, 224).mul_(1.0).type(dtype).requires_grad_()
## torch.randnæ ¹æ®è¾“å…¥çš„shape,è¿”å›çš„æ˜¯normal distribution,å…¶ä¸­mean=0, var=1
## torch.mul_å°±æ˜¯torch.mulçš„åŸåœ°æ“ä½œï¼Œå°±æ˜¯è¿›è¡Œä¹˜æ³•
## torch.requires_grad_()ä¹Ÿæ˜¯åŸåœ°æ“ä½œï¼Œè¡¨ç¤ºéœ€è¦è·Ÿè¸ªæ¢¯åº¦
```

![](https://obsdian-1304266993.cos.ap-chongqing.myqcloud.com/202308111438594.png)

#### é¢„è®­ç»ƒçš„æ¨¡å‹

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬æ˜¯æƒ³è¦å®éªŒå¦‚ä½•å¯è§†åŒ–å·ç§¯ç¥ç»ç½‘ç»œï¼Œå…³å¿ƒä¸­é—´çš„å·ç§¯å±‚åšäº†ä»€ä¹ˆå·¥ä½œï¼Œå·ç§¯æ ¸çš„å…³æ³¨ç‚¹åœ¨å“ªï¼Œå› æ­¤æˆ‘ä»¬é€‰æ‹©ä¸€ä¸ªé¢„è®­ç»ƒå¥½äº†çš„æ¨¡å‹ã€‚æˆ‘ä»¬é€‰æ‹©çš„æ¨¡å‹æ˜¯ã€ŒSqueezeeNetã€ã€‚

{{< notice note >}}

SqueezeNet ï¼Œå…¶ç²¾åº¦ä¸ AlexNet ç›¸å½“ï¼Œä½†å‚æ•°æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦æ˜¾ç€å‡å°‘ã€‚ä½¿ç”¨ SqueezeNet è€Œä¸æ˜¯ AlexNet æˆ– VGG æˆ– ResNet æ„å‘³ç€æˆ‘ä»¬å¯ä»¥è½»æ¾åœ°åœ¨ CPU ä¸Šæ‰§è¡Œæ‰€æœ‰å›¾åƒç”Ÿæˆå®éªŒã€‚

{{< /notice >}}

```python
model = torchvision.models.squeezenet1_1(pretrained=True)
#æ³¨æ„æˆ‘ä»¬æ˜¯ä¸è®­ç»ƒç½‘ç»œçš„ï¼Œæ‰€ä»¥ä¸éœ€è¦è®¡ç®—æ¢¯åº¦
for param in model.parameters():
    param.requires_grad = False
```

#### å¼€å§‹å¯è§†åŒ–

ç°åœ¨æ˜ç¡®æˆ‘ä»¬çš„æ“ä½œæµç¨‹:

1. è¾“å…¥æˆ‘ä»¬åˆå§‹åŒ–çš„imageï¼Œä»¥åŠç›®æ ‡åˆ†ç±»ã€‚
2. å¾—åˆ°imageé€šè¿‡ç½‘ç»œåï¼Œæœ‰å…³ç›®æ ‡åˆ†ç±»çš„å¾—åˆ†ã€‚
3. æ ¹æ®æ¢¯åº¦ï¼Œæ›´æ–°pixelsçš„å€¼ã€‚
4. é‡å¤ä¸Šé¢çš„æ­¥éª¤ã€‚



æˆ‘ä»¬ç»™å‡ºæ­¥éª¤1åˆ°æ­¥éª¤3çš„ï¼Œä»£ç å¦‚ä¸‹:

```py
def class_visualization(model, img, target_y, lr, l2_reg):
  ########################################################################
  # img.shape: (N, C, H, W)
  # target_y: å¸¸é‡
  ###########################################################################
    
    scores = model(img)
    scores = scores[0, target_y]
    scores.backward()
    img_grad = img.grad
    img_grad -= 2 * l2_reg * img
    img.data += lr * img_grad / img_grad.norm()
    img.grad.zero_()
```

ä¸‹é¢æˆ‘ä»¬å°±å¯ä»¥å¼€å§‹iterationsã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¯¾ç¨‹ä¸­å®ç°çš„æ—¶å€™ï¼Œæ¯è½®è¿­ä»£éƒ½ç»™imageåŠ ä¸Šäº†ã€ŒæŠ–åŠ¨ã€(jitter)ã€‚ç›®å‰è¿˜ä¸çŸ¥é“æ˜¯ä¸ºäº†ä»€ä¹ˆï¼ˆæˆ–è®¸æ˜¯åœ¨æ•°æ®å¢å¼ºä¸­ä¸ºå›¾åƒå¢åŠ ä¸€äº›éšæœºæ€§ï¼Œä»è€Œå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°æ³›åŒ–åˆ°æ–°çš„ã€æœªè§è¿‡çš„æ•°æ®ï¼‰ã€‚å®ç°jitterçš„å…·ä½“æ–¹æ³•å°±æ˜¯ï¼Œç»™å®šä¸¤ä¸ªå‚æ•°`ox`,`oy `ï¼š

+ å¦‚æœ `ox` ä¸ä¸º0ï¼Œå‡½æ•°ä¼šå°†å›¾åƒæ²¿ç€å®½åº¦è½´ç§»åŠ¨ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒä¼šå°†å›¾åƒçš„å³ä¾§ `ox` ä¸ªåƒç´ ç§»åŠ¨åˆ°å·¦ä¾§ï¼Œå¹¶å°†å·¦ä¾§çš„å…¶ä½™åƒç´ ç§»åŠ¨åˆ°å³ä¾§ã€‚
+ å¦‚æœ `oy` ä¸ä¸º0ï¼Œå‡½æ•°ä¼šå°†å›¾åƒæ²¿ç€é«˜åº¦è½´ç§»åŠ¨ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒä¼šå°†å›¾åƒçš„åº•éƒ¨ `oy` ä¸ªåƒç´ ç§»åŠ¨åˆ°é¡¶éƒ¨ï¼Œå¹¶å°†é¡¶éƒ¨çš„å…¶ä½™åƒç´ ç§»åŠ¨åˆ°åº•éƒ¨ã€‚

```python
def jitter(X, ox, oy):
    """
    X: PyTorch Tensor of shape (N, C, H, W)
    ox, oy: Integers giving number of pixels to jitter along W and H axes
    """
    if ox != 0:
        left = X[:, :, :, :-ox]
        right = X[:, :, :, -ox:]
        X = torch.cat([right, left], dim=3)
    if oy != 0:
        top = X[:, :, :-oy]
        bottom = X[:, :, -oy:]
        X = torch.cat([bottom, top], dim=2)
    return X
```

åœ¨åŸè¯¾ç¨‹çš„iterationsæ­¥éª¤ä¸­ï¼ŒåŠ å…¥äº†regularizationæ“ä½œï¼Œæˆ‘è¿™é‡Œæ²¡æœ‰åŠ å…¥ï¼Œæ•ˆæœæ˜¯æ²¡æœ‰ä»–çš„å¥½

```python
import random
learning_rate = 25
l2_reg = 1e-3
num_iterations = 100
max_jitter = 16
blur_every = 10
show_every = 25

for t in range(num_iterations):
    ox, oy = random.randint(0, max_jitter), random.randint(0, max_jitter)
    img.data.copy_(jitter(img.data, ox, oy))
    class_visualization(model, img , 76, learning_rate, l2_reg)
    img.data.copy_(jitter(img.data, -ox, -oy)) # undo jitter

     # As regularizer, clamp and periodically blur the image
    # for c in range(3):
    #     lo = float(-SQUEEZENET_MEAN[c] / SQUEEZENET_STD[c])
    #     hi = float((1.0 - SQUEEZENET_MEAN[c]) / SQUEEZENET_STD[c])
    #     img.data[:, c].clamp_(min=lo, max=hi)
    # if t % blur_every == 0:
    #     blur_image(img.data, sigma=0.5)
    #æ¯show_everyæ¬¡æ˜¾ç¤ºä¸€æ¬¡
    if t == 0 or (t + 1) % show_every == 0 or t == num_iterations - 1:
        preprocessed_img = img.data.clone().cpu()
        preprocessed_img = preprocessed_img[0].numpy().transpose(1, 2, 0)
        plt.imshow(preprocessed_img)
        plt.show()

```



ğŸ‘‡æ˜¯è¿­ä»£100æ¬¡çš„ç»“æœ



![image-20230811173838304](https://obsdian-1304266993.cos.ap-chongqing.myqcloud.com/202308111738347.png)

### å¯è§†åŒ–ç‰¹å®šå·ç§¯æ ¸å¯»æ‰¾çš„ç‰¹å¾

å‡è®¾æˆ‘ä»¬ç°åœ¨æœ‰ä¸€ä¸ªç”Ÿæˆçš„å¯è§†åŒ–å·ç§¯æ ¸å›¾$x$ ,æˆ‘ä»¬æƒ³è¦çŸ¥é“ç¬¬$i$å±‚çš„æŸä¸€ä¸ªå·ç§¯æ ¸$j$ ã€Œæ­£åœ¨å¯»æ‰¾çš„ç‰¹å¾ã€ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±æƒ³è¦å½“$x$ä¼ é€’åˆ°å®ƒæ—¶ï¼Œèƒ½è®©å®ƒæœ‰æœ€å¤§çš„æ¿€æ´»å€¼ã€‚

{{< notice note >}}

ä¸ºä»€ä¹ˆæœ‰æœ€å¤§çš„æ¿€æ´»å€¼å¯ä»¥è¯´æ˜å½“å‰çš„$x$æ˜¯ç›®æ ‡å·ç§¯æ ¸å¯»æ‰¾çš„ã€Œç‰¹å¾ã€å‘¢ï¼Ÿè€ƒè™‘äºŒç»´çš„æƒ…å†µï¼Œæˆ‘ä»¬éƒ½çŸ¥é“ä¸¤ä¸ªå‘é‡ä½œç‚¹ä¹˜$v_1 Â·v_2=|v1||v2|cos\theta$ ï¼Œå½“ä¸¤ä¸ªå‘é‡å…±çº¿æ—¶æœ‰æœ€å¤§çš„å€¼ã€‚æˆ‘ä»¬ä»¥æ­¤ä¸ºå¯å‘ï¼Œæˆ‘ä»¬è®¤ä¸ºå¦‚æœ$x$æ‹¥æœ‰ç›®æ ‡å·ç§¯æ ¸æƒ³è¦çš„ç‰¹å¾çš„è¯ï¼Œå®ƒä»¬åœ¨ç©ºé—´ç»´åº¦ä¸Šåº”è¯¥å‘ˆç°å…±çº¿æˆ–è€…è¶‹è¿‘å…±çº¿ï¼Œå› æ­¤å®ƒä»¬ä½œç‚¹ä¹˜çš„å€¼è¶Šå¤§è¶Šå¥½ï¼Œ**ä¹Ÿå°±æ˜¯æ¿€æ´»å€¼è¶Šå¤§ï¼Œè¡¨ç¤º$x$ä¸å·ç§¯æ ¸å¯»æ‰¾çš„ç‰¹å¾è¶Šæ¥è¿‘ã€‚**

{{< /notice >}}



æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä¾ç„¶ä»ä¸€ä¸ªå™ªéŸ³å›¾ç‰‡å‡ºå‘ï¼Œå°†å®ƒè¾“å…¥ç½‘ç»œä¸­è¿›è¡Œå‘å‰ä¼ æ’­ï¼Œæˆ‘ä»¬å¾—åˆ°ç¬¬$i$å±‚çš„æŸä¸€å·ç§¯æ ¸$j$ çš„æ¿€æ´»å€¼$a_{ij}$ï¼Œç„¶ååå‘è®¡ç®—$\frac{da_{ij}}{dx}$ï¼Œå¹¶ç”¨è¿™ä¸ªæ¢¯åº¦æ¥æ›´æ–°$x$,ä¹Ÿå°±æ˜¯æ›´æ–°pixelsçš„å€¼ã€‚
$$
x =x + \eta \frac{da_{ij}}{dx}
$$


## ç¬¬äºŒç±»å¯è§†åŒ–æ–¹æ³•:éå‚æ•°åŒ–

å¯è§†åŒ–å·¥ä½œåˆ†ä¸ºä¸¤å¤§ç±»ï¼Œä¸€ç±»æ˜¯éå‚æ•°åŒ–æ–¹æ³•:è¿™ç§æ–¹æ³•ä¸åˆ†æå·ç§¯æ ¸å…·ä½“çš„å‚æ•°ï¼Œè€Œæ˜¯å…ˆé€‰å–å›¾ç‰‡åº“ï¼Œç„¶åå°†å›¾ç‰‡åœ¨å·²æœ‰æ¨¡å‹ä¸­è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­ï¼Œå¯¹æŸä¸ªå·ç§¯æ ¸ï¼Œæˆ‘ä»¬ä½¿ç”¨å¯¹å…¶å“åº”æœ€å¤§çš„å›¾ç‰‡å—æ¥å¯¹ä¹‹å¯è§†åŒ–;è€Œå¦ä¸€ç±»æ–¹æ³•ç€é‡åˆ†æå·ç§¯æ ¸ä¸­çš„å‚æ•°ï¼Œä½¿ç”¨å‚æ•°é‡æ„å‡ºå›¾åƒã€‚

æˆ‘ä»¬ä¹‹å‰è®²è§£äº†ç¬¬ä¸€ç±»ï¼Œç°åœ¨æ¥è®²ç¬¬äºŒç±»éå‚æ•°åŒ–æ–¹æ³•ã€‚

### pytorchä¸­çš„hook

åœ¨å®ç°ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥ä»‹ç»ä¸€ä¸‹pytorchä¸­çš„hookçš„ä½œç”¨ã€‚å’Œå¾ˆå¤šå…¶ä»–åœ°æ–¹çš„hookä½œç”¨ä¸€æ ·ï¼Œå®ƒæ˜¯åœ¨ç‰¹å®šäº‹ä»¶åè‡ªåŠ¨æ‰§è¡Œçš„å‡½æ•°ã€‚PyTorch ä¸ºæ¯ä¸ªå¼ é‡æˆ– nn.Module å¯¹è±¡æ³¨å†Œ hookã€‚hook ç”±å¯¹è±¡çš„å‘å‰æˆ–å‘åä¼ æ’­è§¦å‘ã€‚å®ƒä»¬å…·æœ‰ä»¥ä¸‹å‡½æ•°ç­¾å:

```python
from torch import nn, Tensor

def module_hook(module: nn.Module, input: Tensor, output: Tensor):
    # For nn.Module objects only.
    
def tensor_hook(grad: Tensor):
    # For Tensor objects only.
    # Only executed during the *backward* pass!
```

### æ­£å¼å¼€å§‹

è¿™æ¬¡ï¼Œæˆ‘ä»¬ä»¥è®­ç»ƒå¥½çš„`ResNet50`ä¸ºæ¨¡å‹ï¼Œè¾“å…¥ä¸€ä¸ªå‡†å¤‡å¥½çš„å›¾ç‰‡ï¼ŒæŸ¥çœ‹æ¯ä¸ªå·ç§¯å±‚æå–åˆ°çš„ç‰¹å¾ã€‚

```python
img_path = 'example.jpg'
img = Image.open(img_path)

#åˆ©ç”¨transformså°†å›¾ç‰‡è½¬æ¢ä¸ºå¯ä»¥å¤„ç†çš„å½¢å¼
transform = transforms.Compose([
    transforms.Resize([224, 224]),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
input_image = transform(img).unsqueeze(0)#(1,3, 224,224)
```

ç„¶åï¼Œæˆ‘ä»¬å°±éœ€è¦å®šä¹‰æˆ‘ä»¬çš„hookå‡½æ•°ã€‚æˆ‘ä»¬ç”¨`get_activation(name)`å‡½æ•°å°†`hook`åŒ…èµ·æ¥ï¼Œè¿™æ ·æ–¹ä¾¿ä¸ºä»»æ„æˆ‘ä»¬æƒ³è¦è§‚æµ‹çš„å·ç§¯å±‚åŠ ä¸Šhookï¼š

```python
activation  = {}
def get_activation(name):
    def hook(model, input, output):
        activation[name] = output.detach()
    return hook
```

æˆ‘ä»¬æ‰“å°æˆ‘ä»¬çš„æ¨¡å‹ï¼Œè§‚å¯Ÿåˆ°ç½‘ç»œç»“æ„å¦‚ä¸‹:

> ResNet(
>   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
>   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
>   (relu): ReLU(inplace=True)
>   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
>   (layer1): Sequential(
>     (0): Bottleneck(
>       (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
>       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
>       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
>       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
>       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
>       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
>       (relu): ReLU(inplace=True)
>       (downsample): Sequential(
>         (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
>         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
>       )
>     )
>     (1): Bottleneck(
>       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
>       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
>       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
>       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
>       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
>       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
>       (relu): ReLU(inplace=True)
>     )
>
> ....
>
> )

å‡å¦‚æˆ‘ä»¬æƒ³è¦çŸ¥é“ï¼Œå°†imageè¾“å…¥åï¼Œlayer2ä¸­çš„ï¼Œç¬¬ä¸€ä¸ªbottleneckçš„conv3å…³æ³¨äº†å“ªäº›ç‰¹å¾ï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿™æ ·æ³¨å†Œ:

```python
model.layer2[0].conv3.register_forward_hook(get_activation('layer2_conv3'))
```

ä¹‹åå°†`input_image`è¾“å…¥æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬çš„`activation`å­—å…¸ä¸­ç”±äºhookè‡ªåŠ¨è§¦å‘ï¼Œå°±æ‹¥æœ‰äº†`layer2_bottleneck1_conv3`çš„æ¿€æ´»å€¼ï¼Œæˆ‘ä»¬é€‰æ‹©ä¸€äº›æ‰“å°å‡ºæ¥ï¼Œå°±å¯ä»¥è¿›è¡Œè§‚å¯Ÿ:

```python
plt.figure(figsize=(12,12))
for i in range(64):
    plt.subplot(8,8,i+1)
    plt.imshow(layer2_conv3[0,i,:,:], cmap='gray')
    plt.axis('off')
plt.show()
```

![image-20230812171432054](https://obsdian-1304266993.cos.ap-chongqing.myqcloud.com/202308121714097.png)
