[分布式相关面试题先来看看简单的分布式系统机架构图 初步了解一下分布式系统是个什么玩意 为什么要将系统进行拆分 要是不拆分 - 掘金](https://juejin.cn/post/6996915693811662884)

# Zookeeper

# MapReduce

MapReduce是谷歌提出来的一个框架，它的思想是，应用程序的设计者只需要编写Map与Reduce函数，而不需要知道有关分布式的任何事情，MapReduce框架处理剩下的事情。

首先MapReduce从集群中选出一个机器当Master,负责分配任务、监督进度、错误处理。然后其他的机器当作是worker。先是给所有的节点安排Map任务，Map任务执行完后再分配Reduce任务。

假设输入的数据已经分片，Master会协调把这些分片分配给worker，但是worker执行Map任务，输出一个中间结果。（输入是kv数据，输出是kv列表，比如说统计单词数量的话，输入是一段文字，输出就是类似某个单词出现的次数这样的kv对）。得到的中间结果还要进行分片，就是对中间结果的键求哈希然后按Reduce任务的数量取余。这样的话同一个key都是由同一个Reduce任务处理。在一个分区中，所有中间k/v都是按key排序的。

所谓map任务，一般是把原始的数据（比如文本，日志）进行初步的数据处理，或者是提取，可以转换为key-value对的中间输出。

reduce任务就是执行聚合计算。

> 可以想一下，如果我们不让一个key被固定的reduce节点处理会发生什么。如果节点1有某个key，节点2也有这个key,为了能正确进行reduce操作，就必须额外进行网络通信来使得一个节点得到完整的kv信息。但是如果我们早早的在map阶段就决定了某个key交给固定的reduce节点来执行，那么就不需要额外的网络通信。

- 心跳信号
  `Worker`只需要向`Master`发送心跳信号表示自身的存活, 如果Master在预定时间内没有收到来自某个`Worker`的心跳，它就会将该`Worker`标记为失效，并将其上运行的所有`Map`和`Reduce`任务重新调度到其他节点上。不过这种设计不太会再`lab 1`中出现, 因为这样会使`Master`记录太多有关`Task`和`Worker`的信息, 设计相对复杂
- 超时重试
  如果一个`Worker`节点在执行`Map`或`Reduce`任务耗时过长，`Master`会检测到这种情况。`Master`将其认定为失败, 可以将失败的任务重新分配给其他健康的`Worker`节点执行。这种重试机制可以处理机器故障、软件错误或其他导致任务失败的问题。
- `checkpoints`
  `Master`会周期性地写入`checkpoints`到磁盘以预备可能的崩溃恢复
- 原子重命名
  将`Map`和`Reduce`任务的输出写入到一个命名好的临时文件，并且只在任务成功完成时才对其进行重命名，来实现任务的幂等性。
- 文件系统备份
  在`MapReduce`框架中，输入数据通常存储在一个分布式文件系统（如`GFS`）中，该文件系统会将数据块复制到多个节点上。这种数据副本机制确保了即使某些机器发生故障，数据仍然可用。